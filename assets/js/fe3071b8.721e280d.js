"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3403],{7145:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"api-reference/audio","title":"Audio API Reference","description":"Comprehensive API documentation for audio services in ConduitLLM, including transcription, text-to-speech, and real-time audio endpoints.","source":"@site/docs/api-reference/audio.md","sourceDirName":"api-reference","slug":"/api-reference/audio","permalink":"/Conduit/docs/api-reference/audio","draft":false,"unlisted":false,"editUrl":"https://github.com/knnlabs/Conduit/tree/main/website/docs/api-reference/audio.md","tags":[],"version":"current","frontMatter":{}}');var t=i(4848),r=i(8453);const o={},a="Audio API Reference",d={},l=[{value:"Transcription API",id:"transcription-api",level:2},{value:"Transcribe Audio",id:"transcribe-audio",level:3},{value:"Translate Audio",id:"translate-audio",level:3},{value:"Text-to-Speech API",id:"text-to-speech-api",level:2},{value:"Create Speech",id:"create-speech",level:3},{value:"Stream Speech",id:"stream-speech",level:3},{value:"Real-time Audio API",id:"real-time-audio-api",level:2},{value:"Create Session",id:"create-session",level:3},{value:"WebSocket Connection",id:"websocket-connection",level:3},{value:"Real-time Events",id:"real-time-events",level:3},{value:"Admin Audio APIs",id:"admin-audio-apis",level:2},{value:"List Audio Providers",id:"list-audio-providers",level:3},{value:"Configure Audio Provider",id:"configure-audio-provider",level:3},{value:"Set Audio Costs",id:"set-audio-costs",level:3},{value:"Get Audio Usage",id:"get-audio-usage",level:3},{value:"Error Responses",id:"error-responses",level:2},{value:"Common Error Codes",id:"common-error-codes",level:3},{value:"Rate Limits",id:"rate-limits",level:2},{value:"Webhooks",id:"webhooks",level:2},{value:"SDK Examples",id:"sdk-examples",level:2},{value:"C# SDK",id:"c-sdk",level:3},{value:"Python SDK",id:"python-sdk",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"audio-api-reference",children:"Audio API Reference"})}),"\n",(0,t.jsx)(n.p,{children:"Comprehensive API documentation for audio services in ConduitLLM, including transcription, text-to-speech, and real-time audio endpoints."}),"\n",(0,t.jsx)(n.h2,{id:"transcription-api",children:"Transcription API"}),"\n",(0,t.jsx)(n.h3,{id:"transcribe-audio",children:"Transcribe Audio"}),"\n",(0,t.jsx)(n.p,{children:"Converts audio to text using speech recognition."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /v1/audio/transcriptions\nContent-Type: multipart/form-data\nX-Virtual-Key: your-virtual-key\n\nParameters:\n- file: Audio file (required)\n- model: Model to use (default: "whisper-1")\n- language: ISO-639-1 language code (optional)\n- prompt: Optional prompt to guide the model\n- response_format: json|text|srt|verbose_json|vtt (default: "json")\n- temperature: Sampling temperature 0-1 (default: 0)\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example Request:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'curl -X POST https://api.conduit.ai/v1/audio/transcriptions \\\n  -H "X-Virtual-Key: your-key" \\\n  -F file="@audio.mp3" \\\n  -F model="whisper-1" \\\n  -F language="en" \\\n  -F response_format="verbose_json"\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example Response (verbose_json):"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "task": "transcribe",\n  "language": "english",\n  "duration": 8.47,\n  "text": "Hello, this is a test of the transcription system.",\n  "segments": [\n    {\n      "id": 0,\n      "seek": 0,\n      "start": 0.0,\n      "end": 3.2,\n      "text": "Hello, this is a test",\n      "tokens": [50364, 15947, 11, 341, 307, 257, 1500],\n      "temperature": 0.0,\n      "avg_logprob": -0.2743,\n      "compression_ratio": 1.235,\n      "no_speech_prob": 0.0012\n    },\n    {\n      "id": 1,\n      "seek": 0,\n      "start": 3.2,\n      "end": 5.8,\n      "text": "of the transcription system.",\n      "tokens": [295, 264, 35288, 1185, 13],\n      "temperature": 0.0,\n      "avg_logprob": -0.1859,\n      "compression_ratio": 1.235,\n      "no_speech_prob": 0.0008\n    }\n  ]\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"translate-audio",children:"Translate Audio"}),"\n",(0,t.jsx)(n.p,{children:"Transcribes audio in any language and translates to English."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /v1/audio/translations\nContent-Type: multipart/form-data\nX-Virtual-Key: your-virtual-key\n\nParameters:\n- file: Audio file (required)\n- model: Model to use (default: "whisper-1")\n- prompt: Optional prompt to guide the model\n- response_format: json|text|srt|verbose_json|vtt (default: "json")\n- temperature: Sampling temperature 0-1 (default: 0)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"text-to-speech-api",children:"Text-to-Speech API"}),"\n",(0,t.jsx)(n.h3,{id:"create-speech",children:"Create Speech"}),"\n",(0,t.jsx)(n.p,{children:"Generates audio from text input."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /v1/audio/speech\nContent-Type: application/json\nX-Virtual-Key: your-virtual-key\n\n{\n  "input": "Text to convert to speech",\n  "model": "tts-1-hd",\n  "voice": "nova",\n  "response_format": "mp3",\n  "speed": 1.0\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Parameters:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input"})," (required): Text to generate audio for (max 4096 chars)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"model"}),' (required): TTS model ID ("tts-1" or "tts-1-hd")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"voice"})," (required): Voice to use (alloy, echo, fable, onyx, nova, shimmer)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"response_format"}),': Audio format - mp3, opus, aac, flac, wav, pcm (default: "mp3")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"speed"}),": Speed of generated audio 0.25-4.0 (default: 1.0)"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Example Response:"})}),"\n",(0,t.jsx)(n.p,{children:"Returns audio file data in the requested format."}),"\n",(0,t.jsx)(n.h3,{id:"stream-speech",children:"Stream Speech"}),"\n",(0,t.jsx)(n.p,{children:"Streams audio generation for lower latency."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /v1/audio/speech/stream\nContent-Type: application/json\nX-Virtual-Key: your-virtual-key\n\n{\n  "input": "Text to stream as speech",\n  "model": "tts-1",\n  "voice": "alloy",\n  "response_format": "opus"\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"Returns chunked audio data via Server-Sent Events (SSE)."}),"\n",(0,t.jsx)(n.h2,{id:"real-time-audio-api",children:"Real-time Audio API"}),"\n",(0,t.jsx)(n.h3,{id:"create-session",children:"Create Session"}),"\n",(0,t.jsx)(n.p,{children:"Establishes a real-time audio session."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /v1/realtime/sessions\nContent-Type: application/json\nX-Virtual-Key: your-virtual-key\n\n{\n  "model": "gpt-4o-realtime-preview",\n  "voice": "alloy",\n  "instructions": "You are a helpful assistant.",\n  "input_audio_format": "pcm16",\n  "output_audio_format": "pcm16",\n  "input_audio_transcription": {\n    "enabled": true,\n    "model": "whisper-1"\n  },\n  "turn_detection": {\n    "type": "server_vad",\n    "threshold": 0.5,\n    "prefix_padding_ms": 300,\n    "silence_duration_ms": 200\n  },\n  "tools": [],\n  "temperature": 0.8,\n  "max_response_output_tokens": 4096\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Response:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "id": "sess_abc123",\n  "object": "realtime.session",\n  "model": "gpt-4o-realtime-preview",\n  "created_at": 1234567890,\n  "expires_at": 1234571490,\n  "status": "created",\n  "ws_url": "wss://api.conduit.ai/v1/realtime/sessions/sess_abc123/ws"\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"websocket-connection",children:"WebSocket Connection"}),"\n",(0,t.jsx)(n.p,{children:"Connect to the session WebSocket for bidirectional audio streaming."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-javascript",children:'const ws = new WebSocket(\'wss://api.conduit.ai/v1/realtime/sessions/sess_abc123/ws\');\n\n// Send audio\nws.send(JSON.stringify({\n  type: "input_audio_buffer.append",\n  audio: btoa(audioData) // base64 encoded PCM16 audio\n}));\n\n// Commit audio buffer to trigger response\nws.send(JSON.stringify({\n  type: "input_audio_buffer.commit"\n}));\n\n// Receive events\nws.onmessage = (event) => {\n  const data = JSON.parse(event.data);\n  \n  switch(data.type) {\n    case "session.created":\n      console.log("Session ready");\n      break;\n      \n    case "response.audio.delta":\n      // Decode and play audio chunk\n      const audio = atob(data.delta);\n      playAudio(audio);\n      break;\n      \n    case "response.text.delta":\n      // Show transcript\n      console.log("Transcript:", data.delta);\n      break;\n      \n    case "response.done":\n      console.log("Response complete");\n      break;\n  }\n};\n'})}),"\n",(0,t.jsx)(n.h3,{id:"real-time-events",children:"Real-time Events"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Client to Server Events:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"session.update"})," - Update session configuration"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_audio_buffer.append"})," - Add audio to input buffer"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_audio_buffer.commit"})," - Process buffered audio"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_audio_buffer.clear"})," - Clear input buffer"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"response.cancel"})," - Cancel in-progress response"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Server to Client Events:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"session.created"})," - Session established"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"session.updated"})," - Configuration updated"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_audio_buffer.speech_started"})," - Speech detected"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_audio_buffer.speech_stopped"})," - Speech ended"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"response.created"})," - Response generation started"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"response.audio.delta"})," - Audio chunk"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"response.text.delta"})," - Transcript chunk"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"response.done"})," - Response complete"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"error"})," - Error occurred"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"admin-audio-apis",children:"Admin Audio APIs"}),"\n",(0,t.jsx)(n.h3,{id:"list-audio-providers",children:"List Audio Providers"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:"GET /api/admin/audio/providers\nX-Master-Key: your-master-key\n"})}),"\n",(0,t.jsx)(n.h3,{id:"configure-audio-provider",children:"Configure Audio Provider"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /api/admin/audio/providers\nContent-Type: application/json\nX-Master-Key: your-master-key\n\n{\n  "providerCredentialId": 1,\n  "transcriptionEnabled": true,\n  "defaultTranscriptionModel": "whisper-1",\n  "textToSpeechEnabled": true,\n  "defaultTTSModel": "tts-1-hd",\n  "defaultTTSVoice": "nova",\n  "realtimeEnabled": true,\n  "defaultRealtimeModel": "gpt-4o-realtime-preview",\n  "routingPriority": 100,\n  "customSettings": {}\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"set-audio-costs",children:"Set Audio Costs"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /api/admin/audio/costs\nContent-Type: application/json\nX-Master-Key: your-master-key\n\n{\n  "provider": "openai",\n  "operationType": "transcription",\n  "model": "whisper-1",\n  "costUnit": "per_minute",\n  "costPerUnit": 0.006,\n  "effectiveDate": "2024-01-01",\n  "isActive": true\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"get-audio-usage",children:"Get Audio Usage"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:"GET /api/admin/audio/usage/summary?startDate=2024-01-01&endDate=2024-12-31\nX-Master-Key: your-master-key\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Response:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "totalOperations": 15420,\n  "totalCost": 92.50,\n  "totalDurationSeconds": 925000,\n  "operationBreakdown": [\n    {\n      "operationType": "transcription",\n      "count": 8500,\n      "totalCost": 51.00,\n      "totalDurationSeconds": 510000,\n      "averageDurationSeconds": 60\n    },\n    {\n      "operationType": "tts",\n      "count": 5920,\n      "totalCost": 29.60,\n      "totalCharacters": 1480000\n    },\n    {\n      "operationType": "realtime",\n      "count": 1000,\n      "totalCost": 11.90,\n      "totalDurationSeconds": 119000\n    }\n  ],\n  "providerBreakdown": [\n    {\n      "provider": "openai",\n      "operationCount": 10000,\n      "totalCost": 65.00\n    },\n    {\n      "provider": "googlecloud",\n      "operationCount": 5420,\n      "totalCost": 27.50\n    }\n  ]\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"error-responses",children:"Error Responses"}),"\n",(0,t.jsx)(n.p,{children:"All endpoints return consistent error responses:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "error": {\n    "code": "invalid_request",\n    "message": "The audio file format is not supported",\n    "type": "validation_error",\n    "param": "file",\n    "details": {\n      "supported_formats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"]\n    }\n  }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"common-error-codes",children:"Common Error Codes"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"invalid_request"})," - Invalid parameters"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"authentication_failed"})," - Invalid API key"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"insufficient_credits"})," - Virtual key limit exceeded"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"model_not_found"})," - Requested model doesn't exist"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"provider_error"})," - Upstream provider error"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"rate_limit_exceeded"})," - Too many requests"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"audio_too_large"})," - File size exceeds limit"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"audio_too_long"})," - Duration exceeds limit"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"rate-limits",children:"Rate Limits"}),"\n",(0,t.jsx)(n.p,{children:"Default rate limits per virtual key:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Transcription: 50 requests/minute, 500 MB/hour"}),"\n",(0,t.jsx)(n.li,{children:"Text-to-Speech: 100 requests/minute, 1M characters/hour"}),"\n",(0,t.jsx)(n.li,{children:"Real-time Sessions: 5 concurrent, 60 minutes/session"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"webhooks",children:"Webhooks"}),"\n",(0,t.jsx)(n.p,{children:"Configure webhooks for async processing:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-http",children:'POST /api/admin/audio/webhooks\nContent-Type: application/json\nX-Master-Key: your-master-key\n\n{\n  "url": "https://your-app.com/webhook",\n  "events": ["transcription.completed", "tts.completed", "realtime.session.ended"],\n  "secret": "webhook-secret",\n  "active": true\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"sdk-examples",children:"SDK Examples"}),"\n",(0,t.jsx)(n.h3,{id:"c-sdk",children:"C# SDK"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'// Initialize client\nvar conduit = new ConduitClient(virtualKey);\n\n// Transcription\nvar transcription = await conduit.Audio.TranscribeAsync(\n    audioFile: File.OpenRead("audio.mp3"),\n    model: "whisper-1",\n    language: "en",\n    responseFormat: TranscriptionFormat.VerboseJson\n);\n\n// Text-to-Speech\nvar audio = await conduit.Audio.CreateSpeechAsync(\n    input: "Hello world",\n    model: "tts-1-hd",\n    voice: "nova"\n);\nFile.WriteAllBytes("output.mp3", audio.AudioData);\n\n// Real-time\nvar session = await conduit.Realtime.CreateSessionAsync(new RealtimeSessionConfig\n{\n    Model = "gpt-4o-realtime-preview",\n    Voice = "alloy"\n});\n\nawait using var stream = await conduit.Realtime.ConnectAsync(session);\n// Stream audio...\n'})}),"\n",(0,t.jsx)(n.h3,{id:"python-sdk",children:"Python SDK"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from conduit import ConduitClient\n\nclient = ConduitClient(api_key="your-virtual-key")\n\n# Transcription\nwith open("audio.mp3", "rb") as audio_file:\n    transcription = client.audio.transcribe(\n        file=audio_file,\n        model="whisper-1",\n        language="en"\n    )\n    print(transcription.text)\n\n# Text-to-Speech\nresponse = client.audio.speech.create(\n    input="Hello world",\n    model="tts-1-hd",\n    voice="nova"\n)\nresponse.stream_to_file("output.mp3")\n'})}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/Conduit/docs/features/audio-services",children:"Audio Services Overview"})," - Learn about audio capabilities"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/Conduit/docs/features/audio-providers",children:"Provider Configuration"})," - Set up audio providers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"/Conduit/docs/guides/budget-management",children:"Cost Management"})," - Control audio costs"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const t={},r=s.createContext(t);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);