"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1848],{8453:(e,n,t)=>{t.d(n,{R:()=>d,x:()=>r});var i=t(6540);const s={},a=i.createContext(s);function d(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),i.createElement(a.Provider,{value:n},e.children)}},9749:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>m,frontMatter:()=>d,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"core-apis/embeddings","title":"Embeddings","description":"Generate vector embeddings for semantic search, RAG, and machine learning applications","source":"@site/docs/core-apis/embeddings.md","sourceDirName":"core-apis","slug":"/core-apis/embeddings","permalink":"/Conduit/docs/core-apis/embeddings","draft":false,"unlisted":false,"editUrl":"https://github.com/knnlabs/Conduit/tree/main/website/docs/core-apis/embeddings.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Embeddings","description":"Generate vector embeddings for semantic search, RAG, and machine learning applications"}}');var s=t(4848),a=t(8453);const d={sidebar_position:3,title:"Embeddings",description:"Generate vector embeddings for semantic search, RAG, and machine learning applications"},r="Embeddings",o={},c=[{value:"Quick Start",id:"quick-start",level:2},{value:"Basic Text Embeddings",id:"basic-text-embeddings",level:3},{value:"Batch Text Embeddings",id:"batch-text-embeddings",level:3},{value:"Supported Models and Providers",id:"supported-models-and-providers",level:2},{value:"OpenAI Embeddings",id:"openai-embeddings",level:3},{value:"Azure OpenAI Embeddings",id:"azure-openai-embeddings",level:3},{value:"Google Vertex AI Embeddings",id:"google-vertex-ai-embeddings",level:3},{value:"Cohere Embeddings",id:"cohere-embeddings",level:3},{value:"Request Parameters",id:"request-parameters",level:2},{value:"Core Parameters",id:"core-parameters",level:3},{value:"Dimensionality Reduction",id:"dimensionality-reduction",level:3},{value:"Encoding Formats",id:"encoding-formats",level:3},{value:"Semantic Search Implementation",id:"semantic-search-implementation",level:2},{value:"Vector Similarity Search",id:"vector-similarity-search",level:3},{value:"RAG (Retrieval-Augmented Generation)",id:"rag-retrieval-augmented-generation",level:3},{value:"Advanced Use Cases",id:"advanced-use-cases",level:2},{value:"Document Clustering",id:"document-clustering",level:3},{value:"Semantic Deduplication",id:"semantic-deduplication",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Batch Processing for Large Datasets",id:"batch-processing-for-large-datasets",level:3},{value:"Caching for Repeated Requests",id:"caching-for-repeated-requests",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Common Embedding Errors",id:"common-embedding-errors",level:3},{value:"Integration Examples",id:"integration-examples",level:2},{value:"Vector Database Integration",id:"vector-database-integration",level:3},{value:"Next Steps",id:"next-steps",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"embeddings",children:"Embeddings"})}),"\n",(0,s.jsx)(n.p,{children:"Conduit's Embeddings API generates high-dimensional vector representations of text, enabling semantic search, retrieval-augmented generation (RAG), clustering, and similarity analysis across multiple providers."}),"\n",(0,s.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsx)(n.h3,{id:"basic-text-embeddings",children:"Basic Text Embeddings"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: 'condt_your_virtual_key',\n  baseURL: 'https://api.conduit.yourdomain.com/v1'\n});\n\nconst response = await openai.embeddings.create({\n  model: 'text-embedding-3-large',\n  input: 'The quick brown fox jumps over the lazy dog',\n  encoding_format: 'float'\n});\n\nconsole.log('Embedding dimensions:', response.data[0].embedding.length);\nconsole.log('First few values:', response.data[0].embedding.slice(0, 5));\n"})}),"\n",(0,s.jsx)(n.h3,{id:"batch-text-embeddings",children:"Batch Text Embeddings"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const texts = [\n  'Artificial intelligence is transforming technology',\n  'Machine learning enables computers to learn from data',\n  'Deep learning uses neural networks with multiple layers',\n  'Natural language processing helps computers understand text'\n];\n\nconst response = await openai.embeddings.create({\n  model: 'text-embedding-3-large',\n  input: texts,\n  encoding_format: 'float'\n});\n\n// Process each embedding\nresponse.data.forEach((embedding, index) => {\n  console.log(`Text ${index + 1}: ${texts[index]}`);\n  console.log(`Embedding length: ${embedding.embedding.length}`);\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"supported-models-and-providers",children:"Supported Models and Providers"}),"\n",(0,s.jsx)(n.h3,{id:"openai-embeddings",children:"OpenAI Embeddings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Dimensions"}),(0,s.jsx)(n.th,{children:"Max Tokens"}),(0,s.jsx)(n.th,{children:"Cost (per 1K tokens)"}),(0,s.jsx)(n.th,{children:"Best For"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"text-embedding-3-large"})}),(0,s.jsx)(n.td,{children:"3072"}),(0,s.jsx)(n.td,{children:"8191"}),(0,s.jsx)(n.td,{children:"$0.13"}),(0,s.jsx)(n.td,{children:"Highest quality, maximum performance"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"text-embedding-3-small"})}),(0,s.jsx)(n.td,{children:"1536"}),(0,s.jsx)(n.td,{children:"8191"}),(0,s.jsx)(n.td,{children:"$0.02"}),(0,s.jsx)(n.td,{children:"Good balance of quality and cost"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"text-embedding-ada-002"})}),(0,s.jsx)(n.td,{children:"1536"}),(0,s.jsx)(n.td,{children:"8191"}),(0,s.jsx)(n.td,{children:"$0.10"}),(0,s.jsx)(n.td,{children:"Legacy model, still reliable"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// High-quality embeddings for critical applications\nconst largeEmbedding = await openai.embeddings.create({\n  model: 'text-embedding-3-large',\n  input: 'Complex technical documentation requiring precise semantic understanding',\n  dimensions: 3072 // Full dimensionality\n});\n\n// Cost-effective embeddings for large-scale processing\nconst smallEmbedding = await openai.embeddings.create({\n  model: 'text-embedding-3-small', \n  input: 'General purpose text for similarity search',\n  dimensions: 1536\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"azure-openai-embeddings",children:"Azure OpenAI Embeddings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Dimensions"}),(0,s.jsx)(n.th,{children:"Max Tokens"}),(0,s.jsx)(n.th,{children:"Cost (per 1K tokens)"}),(0,s.jsx)(n.th,{children:"Deployment"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"text-embedding-3-large"})}),(0,s.jsx)(n.td,{children:"3072"}),(0,s.jsx)(n.td,{children:"8191"}),(0,s.jsx)(n.td,{children:"$0.13"}),(0,s.jsx)(n.td,{children:"Azure deployment required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"text-embedding-3-small"})}),(0,s.jsx)(n.td,{children:"1536"}),(0,s.jsx)(n.td,{children:"8191"}),(0,s.jsx)(n.td,{children:"$0.02"}),(0,s.jsx)(n.td,{children:"Azure deployment required"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"text-embedding-ada-002"})}),(0,s.jsx)(n.td,{children:"1536"}),(0,s.jsx)(n.td,{children:"8191"}),(0,s.jsx)(n.td,{children:"$0.10"}),(0,s.jsx)(n.td,{children:"Azure deployment required"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const azureEmbedding = await openai.embeddings.create({\n  model: 'azure-text-embedding-3-large',\n  input: 'Text to embed using Azure OpenAI',\n  deployment_name: 'your-embedding-deployment' // Azure-specific parameter\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"google-vertex-ai-embeddings",children:"Google Vertex AI Embeddings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Dimensions"}),(0,s.jsx)(n.th,{children:"Max Tokens"}),(0,s.jsx)(n.th,{children:"Cost (per 1K tokens)"}),(0,s.jsx)(n.th,{children:"Best For"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"textembedding-gecko"})}),(0,s.jsx)(n.td,{children:"768"}),(0,s.jsx)(n.td,{children:"3072"}),(0,s.jsx)(n.td,{children:"$0.025"}),(0,s.jsx)(n.td,{children:"Multilingual support"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"textembedding-gecko-multilingual"})}),(0,s.jsx)(n.td,{children:"768"}),(0,s.jsx)(n.td,{children:"3072"}),(0,s.jsx)(n.td,{children:"$0.025"}),(0,s.jsx)(n.td,{children:"100+ languages"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const googleEmbedding = await openai.embeddings.create({\n  model: 'textembedding-gecko',\n  input: 'Text to embed using Google Vertex AI',\n  task_type: 'RETRIEVAL_DOCUMENT' // Google-specific task optimization\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"cohere-embeddings",children:"Cohere Embeddings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Dimensions"}),(0,s.jsx)(n.th,{children:"Max Tokens"}),(0,s.jsx)(n.th,{children:"Cost (per 1K tokens)"}),(0,s.jsx)(n.th,{children:"Best For"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"embed-english-v3.0"})}),(0,s.jsx)(n.td,{children:"1024"}),(0,s.jsx)(n.td,{children:"512"}),(0,s.jsx)(n.td,{children:"$0.10"}),(0,s.jsx)(n.td,{children:"English text optimization"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"embed-multilingual-v3.0"})}),(0,s.jsx)(n.td,{children:"1024"}),(0,s.jsx)(n.td,{children:"512"}),(0,s.jsx)(n.td,{children:"$0.10"}),(0,s.jsx)(n.td,{children:"100+ languages"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"embed-english-light-v3.0"})}),(0,s.jsx)(n.td,{children:"384"}),(0,s.jsx)(n.td,{children:"512"}),(0,s.jsx)(n.td,{children:"$0.05"}),(0,s.jsx)(n.td,{children:"Fast, lightweight processing"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const cohereEmbedding = await openai.embeddings.create({\n  model: 'embed-english-v3.0',\n  input: 'Text to embed using Cohere',\n  input_type: 'search_document', // Cohere-specific optimization\n  truncate: 'END' // Handle long texts\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"request-parameters",children:"Request Parameters"}),"\n",(0,s.jsx)(n.h3,{id:"core-parameters",children:"Core Parameters"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"const response = await openai.embeddings.create({\n  // Required parameters\n  model: 'text-embedding-3-large',     // Embedding model\n  input: 'Text to embed',              // String or array of strings\n  \n  // Optional parameters\n  encoding_format: 'float',            // 'float' or 'base64'\n  dimensions: 1536,                    // Reduce dimensionality (if supported)\n  user: 'user-123',                    // User tracking\n  \n  // Provider-specific parameters\n  task_type: 'RETRIEVAL_DOCUMENT',     // Google: task optimization\n  input_type: 'search_document',       // Cohere: input type\n  truncate: 'END'                      // Cohere: truncation strategy\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"dimensionality-reduction",children:"Dimensionality Reduction"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// OpenAI supports dimensionality reduction for efficiency\nconst reducedEmbedding = await openai.embeddings.create({\n  model: 'text-embedding-3-large',\n  input: 'Text to embed with reduced dimensions',\n  dimensions: 1024 // Reduce from 3072 to 1024 dimensions\n});\n\n// Benefits: Smaller storage, faster similarity calculations\n// Trade-off: Slight reduction in semantic precision\n"})}),"\n",(0,s.jsx)(n.h3,{id:"encoding-formats",children:"Encoding Formats"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Float format (default) - for direct computation\nconst floatEmbedding = await openai.embeddings.create({\n  model: 'text-embedding-3-small',\n  input: 'Text for float encoding',\n  encoding_format: 'float'\n});\n\n// Base64 format - for compact transmission/storage\nconst base64Embedding = await openai.embeddings.create({\n  model: 'text-embedding-3-small', \n  input: 'Text for base64 encoding',\n  encoding_format: 'base64'\n});\n\n// Convert base64 back to float array\nfunction base64ToFloat(base64String) {\n  const binaryString = atob(base64String);\n  const floatArray = new Float32Array(binaryString.length / 4);\n  \n  for (let i = 0; i < floatArray.length; i++) {\n    const offset = i * 4;\n    const bytes = [\n      binaryString.charCodeAt(offset),\n      binaryString.charCodeAt(offset + 1), \n      binaryString.charCodeAt(offset + 2),\n      binaryString.charCodeAt(offset + 3)\n    ];\n    \n    const dataView = new DataView(new ArrayBuffer(4));\n    bytes.forEach((byte, index) => dataView.setUint8(index, byte));\n    floatArray[i] = dataView.getFloat32(0, true);\n  }\n  \n  return Array.from(floatArray);\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"semantic-search-implementation",children:"Semantic Search Implementation"}),"\n",(0,s.jsx)(n.h3,{id:"vector-similarity-search",children:"Vector Similarity Search"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"class SemanticSearch {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n    this.documents = [];\n    this.embeddings = [];\n  }\n\n  async addDocument(text, metadata = {}) {\n    // Generate embedding for the document\n    const response = await this.openai.embeddings.create({\n      model: 'text-embedding-3-large',\n      input: text\n    });\n\n    const embedding = response.data[0].embedding;\n    \n    this.documents.push({ text, metadata });\n    this.embeddings.push(embedding);\n    \n    return this.documents.length - 1; // Return document index\n  }\n\n  async search(query, topK = 5) {\n    // Generate embedding for the query\n    const response = await this.openai.embeddings.create({\n      model: 'text-embedding-3-large',\n      input: query\n    });\n\n    const queryEmbedding = response.data[0].embedding;\n    \n    // Calculate similarities\n    const similarities = this.embeddings.map((docEmbedding, index) => ({\n      index,\n      similarity: this.cosineSimilarity(queryEmbedding, docEmbedding),\n      document: this.documents[index]\n    }));\n\n    // Sort by similarity and return top K\n    return similarities\n      .sort((a, b) => b.similarity - a.similarity)\n      .slice(0, topK);\n  }\n\n  cosineSimilarity(a, b) {\n    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);\n    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));\n    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));\n    \n    return dotProduct / (magnitudeA * magnitudeB);\n  }\n}\n\n// Usage example\nconst search = new SemanticSearch('condt_your_virtual_key');\n\n// Add documents to search index\nawait search.addDocument(\n  'Machine learning is a subset of artificial intelligence',\n  { category: 'AI', source: 'textbook' }\n);\n\nawait search.addDocument(\n  'Deep learning uses neural networks with multiple layers',\n  { category: 'AI', source: 'research paper' }\n);\n\nawait search.addDocument(\n  'Python is a popular programming language for data science',\n  { category: 'Programming', source: 'tutorial' }\n);\n\n// Search for similar documents\nconst results = await search.search('What is artificial intelligence?', 3);\n\nresults.forEach((result, index) => {\n  console.log(`${index + 1}. Similarity: ${result.similarity.toFixed(3)}`);\n  console.log(`   Text: ${result.document.text}`);\n  console.log(`   Category: ${result.document.metadata.category}`);\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"rag-retrieval-augmented-generation",children:"RAG (Retrieval-Augmented Generation)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"class RAGSystem {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n    this.knowledgeBase = new SemanticSearch(apiKey);\n  }\n\n  async addKnowledge(documents) {\n    for (const doc of documents) {\n      await this.knowledgeBase.addDocument(doc.content, doc.metadata);\n    }\n  }\n\n  async generateAnswer(question, topK = 3) {\n    // Retrieve relevant documents\n    const relevantDocs = await this.knowledgeBase.search(question, topK);\n    \n    // Construct context from retrieved documents\n    const context = relevantDocs\n      .map((doc, index) => `[${index + 1}] ${doc.document.text}`)\n      .join('\\n\\n');\n\n    // Generate answer using retrieved context\n    const completion = await this.openai.chat.completions.create({\n      model: 'gpt-4',\n      messages: [\n        {\n          role: 'system',\n          content: `You are a helpful assistant. Use the following context to answer the user's question. If the answer cannot be found in the context, say so clearly.\n\nContext:\n${context}`\n        },\n        {\n          role: 'user',\n          content: question\n        }\n      ],\n      max_tokens: 500,\n      temperature: 0.1\n    });\n\n    return {\n      answer: completion.choices[0].message.content,\n      sources: relevantDocs.map(doc => ({\n        text: doc.document.text,\n        similarity: doc.similarity,\n        metadata: doc.document.metadata\n      }))\n    };\n  }\n}\n\n// Usage example\nconst rag = new RAGSystem('condt_your_virtual_key');\n\n// Add knowledge base\nawait rag.addKnowledge([\n  {\n    content: 'The capital of France is Paris. Paris is known for the Eiffel Tower and the Louvre Museum.',\n    metadata: { topic: 'geography', country: 'France' }\n  },\n  {\n    content: 'Machine learning algorithms can be supervised, unsupervised, or reinforcement learning.',\n    metadata: { topic: 'technology', subject: 'AI' }\n  },\n  {\n    content: 'Photosynthesis is the process by which plants convert sunlight into energy.',\n    metadata: { topic: 'science', subject: 'biology' }\n  }\n]);\n\n// Ask questions and get context-aware answers\nconst result = await rag.generateAnswer('What is the capital of France?');\nconsole.log('Answer:', result.answer);\nconsole.log('Sources:', result.sources);\n"})}),"\n",(0,s.jsx)(n.h2,{id:"advanced-use-cases",children:"Advanced Use Cases"}),"\n",(0,s.jsx)(n.h3,{id:"document-clustering",children:"Document Clustering"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"class DocumentClustering {\n  constructor(apiKey) {\n    this.apiKey = apiKey;\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n  }\n\n  async clusterDocuments(documents, numClusters = 3) {\n    // Generate embeddings for all documents\n    const embeddings = [];\n    \n    for (const doc of documents) {\n      const response = await this.openai.embeddings.create({\n        model: 'text-embedding-3-small',\n        input: doc.text\n      });\n      \n      embeddings.push({\n        text: doc.text,\n        embedding: response.data[0].embedding,\n        metadata: doc.metadata || {}\n      });\n    }\n\n    // Simple K-means clustering implementation\n    const clusters = this.kMeansClustering(embeddings, numClusters);\n    \n    return clusters;\n  }\n\n  kMeansClustering(embeddings, k) {\n    const dimensions = embeddings[0].embedding.length;\n    \n    // Initialize random centroids\n    let centroids = Array.from({ length: k }, () => \n      Array.from({ length: dimensions }, () => Math.random() - 0.5)\n    );\n\n    let assignments = new Array(embeddings.length);\n    let converged = false;\n    let iterations = 0;\n    const maxIterations = 100;\n\n    while (!converged && iterations < maxIterations) {\n      // Assign each point to nearest centroid\n      const newAssignments = embeddings.map((emb, index) => {\n        let minDistance = Infinity;\n        let closestCentroid = 0;\n\n        centroids.forEach((centroid, centroidIndex) => {\n          const distance = this.euclideanDistance(emb.embedding, centroid);\n          if (distance < minDistance) {\n            minDistance = distance;\n            closestCentroid = centroidIndex;\n          }\n        });\n\n        return closestCentroid;\n      });\n\n      // Check for convergence\n      converged = assignments.every((assignment, index) => \n        assignment === newAssignments[index]\n      );\n      \n      assignments = newAssignments;\n\n      // Update centroids\n      if (!converged) {\n        centroids = centroids.map((_, centroidIndex) => {\n          const clusterPoints = embeddings.filter((_, pointIndex) => \n            assignments[pointIndex] === centroidIndex\n          );\n\n          if (clusterPoints.length === 0) return centroids[centroidIndex];\n\n          return Array.from({ length: dimensions }, (_, dim) => {\n            const sum = clusterPoints.reduce((acc, point) => \n              acc + point.embedding[dim], 0\n            );\n            return sum / clusterPoints.length;\n          });\n        });\n      }\n\n      iterations++;\n    }\n\n    // Group documents by cluster\n    const clusters = Array.from({ length: k }, () => []);\n    embeddings.forEach((emb, index) => {\n      clusters[assignments[index]].push({\n        text: emb.text,\n        metadata: emb.metadata\n      });\n    });\n\n    return clusters;\n  }\n\n  euclideanDistance(a, b) {\n    return Math.sqrt(a.reduce((sum, val, i) => sum + Math.pow(val - b[i], 2), 0));\n  }\n}\n\n// Usage example\nconst clustering = new DocumentClustering('condt_your_virtual_key');\n\nconst documents = [\n  { text: 'Machine learning models require training data' },\n  { text: 'Deep neural networks have multiple layers' },\n  { text: 'Natural language processing analyzes text' },\n  { text: 'Computer vision processes images' },\n  { text: 'The weather is sunny today' },\n  { text: 'Rain is expected tomorrow' },\n  { text: 'Clouds are forming in the sky' },\n  { text: 'Basketball is a popular sport' },\n  { text: 'Football has many fans worldwide' },\n  { text: 'Tennis requires good hand-eye coordination' }\n];\n\nconst clusters = await clustering.clusterDocuments(documents, 3);\n\nclusters.forEach((cluster, index) => {\n  console.log(`\\nCluster ${index + 1}:`);\n  cluster.forEach(doc => {\n    console.log(`  - ${doc.text}`);\n  });\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"semantic-deduplication",children:"Semantic Deduplication"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"class SemanticDeduplication {\n  constructor(apiKey, similarityThreshold = 0.9) {\n    this.apiKey = apiKey;\n    this.similarityThreshold = similarityThreshold;\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n  }\n\n  async deduplicateDocuments(documents) {\n    const embeddings = [];\n    \n    // Generate embeddings\n    for (const doc of documents) {\n      const response = await this.openai.embeddings.create({\n        model: 'text-embedding-3-small',\n        input: doc.text\n      });\n      \n      embeddings.push({\n        ...doc,\n        embedding: response.data[0].embedding\n      });\n    }\n\n    const unique = [];\n    const duplicates = [];\n\n    for (let i = 0; i < embeddings.length; i++) {\n      let isDuplicate = false;\n      \n      for (let j = 0; j < unique.length; j++) {\n        const similarity = this.cosineSimilarity(\n          embeddings[i].embedding,\n          unique[j].embedding\n        );\n        \n        if (similarity >= this.similarityThreshold) {\n          duplicates.push({\n            original: unique[j],\n            duplicate: embeddings[i],\n            similarity: similarity\n          });\n          isDuplicate = true;\n          break;\n        }\n      }\n      \n      if (!isDuplicate) {\n        unique.push(embeddings[i]);\n      }\n    }\n\n    return {\n      unique: unique.map(doc => ({ text: doc.text, metadata: doc.metadata })),\n      duplicates: duplicates\n    };\n  }\n\n  cosineSimilarity(a, b) {\n    const dotProduct = a.reduce((sum, val, i) => sum + val * b[i], 0);\n    const magnitudeA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));\n    const magnitudeB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));\n    \n    return dotProduct / (magnitudeA * magnitudeB);\n  }\n}\n\n// Usage example\nconst deduplication = new SemanticDeduplication('condt_your_virtual_key', 0.85);\n\nconst documents = [\n  { text: 'Machine learning is a subset of artificial intelligence' },\n  { text: 'ML is part of the broader field of AI' }, // Similar to above\n  { text: 'Deep learning uses neural networks' },\n  { text: 'The weather is sunny today' },\n  { text: 'It is a bright and sunny day' }, // Similar to above\n  { text: 'Python is a programming language' }\n];\n\nconst result = await deduplication.deduplicateDocuments(documents);\n\nconsole.log('Unique documents:');\nresult.unique.forEach((doc, index) => {\n  console.log(`${index + 1}. ${doc.text}`);\n});\n\nconsole.log('\\nDuplicates found:');\nresult.duplicates.forEach((dup, index) => {\n  console.log(`${index + 1}. Similarity: ${dup.similarity.toFixed(3)}`);\n  console.log(`   Original: ${dup.original.text}`);\n  console.log(`   Duplicate: ${dup.duplicate.text}`);\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"batch-processing-for-large-datasets",children:"Batch Processing for Large Datasets"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"class BatchEmbeddingProcessor {\n  constructor(apiKey, batchSize = 100, concurrency = 5) {\n    this.apiKey = apiKey;\n    this.batchSize = batchSize;\n    this.concurrency = concurrency;\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n  }\n\n  async processLargeDataset(texts, model = 'text-embedding-3-small') {\n    const results = [];\n    const batches = this.createBatches(texts);\n    \n    console.log(`Processing ${texts.length} texts in ${batches.length} batches`);\n\n    // Process batches with controlled concurrency\n    for (let i = 0; i < batches.length; i += this.concurrency) {\n      const batchGroup = batches.slice(i, i + this.concurrency);\n      \n      const batchPromises = batchGroup.map(async (batch, batchIndex) => {\n        const actualBatchIndex = i + batchIndex;\n        console.log(`Processing batch ${actualBatchIndex + 1}/${batches.length}`);\n        \n        try {\n          const response = await this.openai.embeddings.create({\n            model: model,\n            input: batch\n          });\n          \n          return response.data.map(item => item.embedding);\n        } catch (error) {\n          console.error(`Batch ${actualBatchIndex + 1} failed:`, error.message);\n          throw error;\n        }\n      });\n\n      const batchResults = await Promise.all(batchPromises);\n      results.push(...batchResults.flat());\n      \n      // Rate limiting pause between batch groups\n      if (i + this.concurrency < batches.length) {\n        await new Promise(resolve => setTimeout(resolve, 1000));\n      }\n    }\n\n    return results;\n  }\n\n  createBatches(texts) {\n    const batches = [];\n    for (let i = 0; i < texts.length; i += this.batchSize) {\n      batches.push(texts.slice(i, i + this.batchSize));\n    }\n    return batches;\n  }\n\n  async processWithRetry(texts, model, maxRetries = 3) {\n    for (let attempt = 1; attempt <= maxRetries; attempt++) {\n      try {\n        return await this.processLargeDataset(texts, model);\n      } catch (error) {\n        console.log(`Attempt ${attempt} failed:`, error.message);\n        \n        if (attempt === maxRetries) {\n          throw error;\n        }\n        \n        // Exponential backoff\n        const delay = Math.pow(2, attempt) * 1000;\n        console.log(`Retrying in ${delay}ms...`);\n        await new Promise(resolve => setTimeout(resolve, delay));\n      }\n    }\n  }\n}\n\n// Usage for large datasets\nconst processor = new BatchEmbeddingProcessor('condt_your_virtual_key', 50, 3);\n\nconst largeDataset = Array.from({ length: 1000 }, (_, i) => \n  `This is document number ${i + 1} with some sample content.`\n);\n\nconst embeddings = await processor.processWithRetry(\n  largeDataset, \n  'text-embedding-3-small'\n);\n\nconsole.log(`Generated ${embeddings.length} embeddings`);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"caching-for-repeated-requests",children:"Caching for Repeated Requests"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"class EmbeddingCache {\n  constructor(apiKey, ttlMinutes = 60) {\n    this.apiKey = apiKey;\n    this.cache = new Map();\n    this.ttl = ttlMinutes * 60 * 1000; // Convert to milliseconds\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n  }\n\n  getCacheKey(text, model) {\n    return crypto.createHash('md5')\n      .update(JSON.stringify({ text, model }))\n      .digest('hex');\n  }\n\n  async getEmbedding(text, model = 'text-embedding-3-small') {\n    const cacheKey = this.getCacheKey(text, model);\n    const cached = this.cache.get(cacheKey);\n    \n    // Check if cached and not expired\n    if (cached && Date.now() - cached.timestamp < this.ttl) {\n      console.log('Using cached embedding');\n      return cached.embedding;\n    }\n\n    // Generate new embedding\n    console.log('Generating new embedding');\n    const response = await this.openai.embeddings.create({\n      model: model,\n      input: text\n    });\n\n    const embedding = response.data[0].embedding;\n    \n    // Cache the result\n    this.cache.set(cacheKey, {\n      embedding: embedding,\n      timestamp: Date.now()\n    });\n\n    return embedding;\n  }\n\n  async getBatchEmbeddings(texts, model = 'text-embedding-3-small') {\n    const embeddings = [];\n    const uncachedTexts = [];\n    const uncachedIndices = [];\n\n    // Check cache for each text\n    for (let i = 0; i < texts.length; i++) {\n      const cacheKey = this.getCacheKey(texts[i], model);\n      const cached = this.cache.get(cacheKey);\n      \n      if (cached && Date.now() - cached.timestamp < this.ttl) {\n        embeddings[i] = cached.embedding;\n      } else {\n        uncachedTexts.push(texts[i]);\n        uncachedIndices.push(i);\n      }\n    }\n\n    // Generate embeddings for uncached texts\n    if (uncachedTexts.length > 0) {\n      console.log(`Generating ${uncachedTexts.length} new embeddings`);\n      \n      const response = await this.openai.embeddings.create({\n        model: model,\n        input: uncachedTexts\n      });\n\n      // Cache new embeddings and fill results\n      response.data.forEach((item, index) => {\n        const originalIndex = uncachedIndices[index];\n        const text = texts[originalIndex];\n        const embedding = item.embedding;\n        \n        // Cache the result\n        const cacheKey = this.getCacheKey(text, model);\n        this.cache.set(cacheKey, {\n          embedding: embedding,\n          timestamp: Date.now()\n        });\n        \n        embeddings[originalIndex] = embedding;\n      });\n    }\n\n    console.log(`Cache hits: ${texts.length - uncachedTexts.length}/${texts.length}`);\n    return embeddings;\n  }\n\n  clearExpiredCache() {\n    const now = Date.now();\n    for (const [key, value] of this.cache.entries()) {\n      if (now - value.timestamp >= this.ttl) {\n        this.cache.delete(key);\n      }\n    }\n  }\n\n  getCacheStats() {\n    return {\n      size: this.cache.size,\n      memoryUsage: this.cache.size * 1536 * 4, // Approximate bytes for 1536-dim embeddings\n      ttlMinutes: this.ttl / (60 * 1000)\n    };\n  }\n}\n\n// Usage example\nconst embeddingCache = new EmbeddingCache('condt_your_virtual_key', 30);\n\n// These will be generated fresh\nconst embedding1 = await embeddingCache.getEmbedding('First text');\nconst embedding2 = await embeddingCache.getEmbedding('Second text');\n\n// This will use cache\nconst embedding1Cached = await embeddingCache.getEmbedding('First text');\n\nconsole.log('Cache stats:', embeddingCache.getCacheStats());\n"})}),"\n",(0,s.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,s.jsx)(n.h3,{id:"common-embedding-errors",children:"Common Embedding Errors"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"async function robustEmbeddingGeneration(text, model = 'text-embedding-3-small') {\n  try {\n    const response = await openai.embeddings.create({\n      model: model,\n      input: text\n    });\n    \n    return response.data[0].embedding;\n  } catch (error) {\n    switch (error.code) {\n      case 'context_length_exceeded':\n        console.log('Text too long, truncating...');\n        const truncatedText = text.substring(0, 8000); // Safe limit\n        return robustEmbeddingGeneration(truncatedText, model);\n        \n      case 'rate_limit_exceeded':\n        console.log('Rate limited, waiting...');\n        await new Promise(resolve => setTimeout(resolve, 60000)); // Wait 1 minute\n        return robustEmbeddingGeneration(text, model);\n        \n      case 'insufficient_quota':\n        console.log('Quota exceeded, switching to smaller model...');\n        if (model === 'text-embedding-3-large') {\n          return robustEmbeddingGeneration(text, 'text-embedding-3-small');\n        }\n        throw error;\n        \n      case 'model_not_available':\n        console.log('Model unavailable, using fallback...');\n        return robustEmbeddingGeneration(text, 'text-embedding-ada-002');\n        \n      default:\n        console.error('Embedding generation failed:', error.message);\n        throw error;\n    }\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"integration-examples",children:"Integration Examples"}),"\n",(0,s.jsx)(n.h3,{id:"vector-database-integration",children:"Vector Database Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// Example with Pinecone vector database\nclass PineconeIntegration {\n  constructor(apiKey, pineconeConfig) {\n    this.apiKey = apiKey;\n    this.openai = new OpenAI({\n      apiKey: apiKey,\n      baseURL: 'https://api.conduit.yourdomain.com/v1'\n    });\n    this.pinecone = new Pinecone(pineconeConfig);\n  }\n\n  async indexDocument(id, text, metadata = {}) {\n    // Generate embedding\n    const response = await this.openai.embeddings.create({\n      model: 'text-embedding-3-large',\n      input: text\n    });\n\n    const embedding = response.data[0].embedding;\n\n    // Store in Pinecone\n    await this.pinecone.upsert([{\n      id: id,\n      values: embedding,\n      metadata: { text, ...metadata }\n    }]);\n\n    return id;\n  }\n\n  async searchSimilar(query, topK = 10) {\n    // Generate query embedding\n    const response = await this.openai.embeddings.create({\n      model: 'text-embedding-3-large',\n      input: query\n    });\n\n    const queryEmbedding = response.data[0].embedding;\n\n    // Search Pinecone\n    const results = await this.pinecone.query({\n      vector: queryEmbedding,\n      topK: topK,\n      includeMetadata: true\n    });\n\n    return results.matches;\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Chat Completions"}),": Combine embeddings with ",(0,s.jsx)(n.a,{href:"chat-completions",children:"chat completions"})," for RAG"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Models Endpoint"}),": Discover available ",(0,s.jsx)(n.a,{href:"models",children:"embedding models"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Audio Platform"}),": Explore ",(0,s.jsx)(n.a,{href:"../audio/speech-to-text",children:"speech-to-text embeddings"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Integration Examples"}),": See complete ",(0,s.jsx)(n.a,{href:"../clients/overview",children:"client patterns"})]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}}}]);