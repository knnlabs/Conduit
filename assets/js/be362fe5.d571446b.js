"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9281],{478:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"audio/real-time-audio","title":"Real-Time Audio","description":"WebSocket proxy for real-time audio connections to provider APIs","source":"@site/docs/audio/real-time-audio.md","sourceDirName":"audio","slug":"/audio/real-time-audio","permalink":"/Conduit/docs/audio/real-time-audio","draft":false,"unlisted":false,"editUrl":"https://github.com/knnlabs/Conduit/tree/main/website/docs/audio/real-time-audio.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Real-Time Audio","description":"WebSocket proxy for real-time audio connections to provider APIs"},"sidebar":"docsSidebar","previous":{"title":"Text-to-Speech","permalink":"/Conduit/docs/audio/text-to-speech"},"next":{"title":"Image Generation","permalink":"/Conduit/docs/media/image-generation"}}');var o=i(4848),s=i(8453);const r={sidebar_position:4,title:"Real-Time Audio",description:"WebSocket proxy for real-time audio connections to provider APIs"},a="Real-Time Audio",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Supported Providers",id:"supported-providers",level:2},{value:"Connection",id:"connection",level:2},{value:"WebSocket Endpoint",id:"websocket-endpoint",level:3},{value:"Connection Parameters",id:"connection-parameters",level:3},{value:"Authentication",id:"authentication",level:3},{value:"Basic Implementation",id:"basic-implementation",level:2},{value:"Simple WebSocket Client",id:"simple-websocket-client",level:3},{value:"Usage Example",id:"usage-example",level:3},{value:"Provider-Specific Usage",id:"provider-specific-usage",level:2},{value:"OpenAI Realtime API",id:"openai-realtime-api",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Connection Errors",id:"connection-errors",level:3},{value:"Message Validation",id:"message-validation",level:3},{value:"Monitoring and Debugging",id:"monitoring-and-debugging",level:2},{value:"Connection Monitoring",id:"connection-monitoring",level:3},{value:"Limitations",id:"limitations",level:2},{value:"Current Implementation",id:"current-implementation",level:3},{value:"Best Practices",id:"best-practices",level:3},{value:"Next Steps",id:"next-steps",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"real-time-audio",children:"Real-Time Audio"})}),"\n",(0,o.jsx)(n.p,{children:"Conduit provides a WebSocket proxy for real-time audio connections to supported providers. This allows applications to establish direct WebSocket connections through Conduit while maintaining virtual key authentication and provider routing."}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsxs)(n.p,{children:["Real-time audio in Conduit works as a ",(0,o.jsx)(n.strong,{children:"WebSocket proxy"}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Authenticates requests using virtual keys"}),"\n",(0,o.jsx)(n.li,{children:"Routes connections to appropriate providers"}),"\n",(0,o.jsx)(n.li,{children:"Proxies WebSocket messages bidirectionally"}),"\n",(0,o.jsx)(n.li,{children:"Maintains connection state and error handling"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"supported-providers",children:"Supported Providers"}),"\n",(0,o.jsx)(n.p,{children:"Currently, real-time audio proxy supports providers that offer WebSocket-based real-time audio APIs."}),"\n",(0,o.jsx)(n.h2,{id:"connection",children:"Connection"}),"\n",(0,o.jsx)(n.h3,{id:"websocket-endpoint",children:"WebSocket Endpoint"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"wss://api.conduit.yourdomain.com/v1/realtime/connect\n"})}),"\n",(0,o.jsx)(n.h3,{id:"connection-parameters",children:"Connection Parameters"}),"\n",(0,o.jsx)(n.p,{children:"Connect with model and provider specified as query parameters:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"const websocket = new WebSocket(\n  'wss://api.conduit.yourdomain.com/v1/realtime/connect?model=gpt-4o-realtime-preview&provider=openai',\n  {\n    headers: {\n      'Authorization': 'Bearer condt_your_virtual_key'\n    }\n  }\n);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"authentication",children:"Authentication"}),"\n",(0,o.jsxs)(n.p,{children:["Real-time audio connections require virtual key authentication via the ",(0,o.jsx)(n.code,{children:"Authorization"})," header:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"const ws = new WebSocket(websocketUrl, {\n  headers: {\n    'Authorization': 'Bearer condt_your_virtual_key'\n  }\n});\n"})}),"\n",(0,o.jsx)(n.h2,{id:"basic-implementation",children:"Basic Implementation"}),"\n",(0,o.jsx)(n.h3,{id:"simple-websocket-client",children:"Simple WebSocket Client"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"class ConduitRealTimeAudio {\n  constructor(apiKey, model = 'gpt-4o-realtime-preview', provider = 'openai') {\n    this.apiKey = apiKey;\n    this.model = model;\n    this.provider = provider;\n    this.ws = null;\n    this.isConnected = false;\n  }\n\n  connect() {\n    const url = `wss://api.conduit.yourdomain.com/v1/realtime/connect?model=${this.model}&provider=${this.provider}`;\n    \n    this.ws = new WebSocket(url, {\n      headers: {\n        'Authorization': `Bearer ${this.apiKey}`\n      }\n    });\n\n    this.ws.on('open', () => {\n      console.log('Connected to Conduit real-time audio proxy');\n      this.isConnected = true;\n    });\n\n    this.ws.on('message', (data) => {\n      this.handleMessage(data);\n    });\n\n    this.ws.on('close', (code, reason) => {\n      console.log(`Connection closed: ${code} ${reason}`);\n      this.isConnected = false;\n    });\n\n    this.ws.on('error', (error) => {\n      console.error('WebSocket error:', error);\n    });\n  }\n\n  handleMessage(data) {\n    try {\n      // Handle both text and binary messages\n      if (data instanceof Buffer) {\n        console.log('Received binary data:', data.length, 'bytes');\n        this.onAudioData(data);\n      } else {\n        const message = JSON.parse(data);\n        console.log('Received text message:', message);\n        this.onTextMessage(message);\n      }\n    } catch (error) {\n      console.error('Error handling message:', error);\n    }\n  }\n\n  send(data) {\n    if (this.ws && this.isConnected) {\n      this.ws.send(data);\n    } else {\n      console.error('WebSocket not connected');\n    }\n  }\n\n  sendText(message) {\n    this.send(JSON.stringify(message));\n  }\n\n  sendAudio(audioBuffer) {\n    this.send(audioBuffer);\n  }\n\n  onTextMessage(message) {\n    // Override in subclass to handle provider-specific text messages\n    console.log('Text message:', message);\n  }\n\n  onAudioData(audioBuffer) {\n    // Override in subclass to handle audio data\n    console.log('Audio data received:', audioBuffer.length, 'bytes');\n  }\n\n  disconnect() {\n    if (this.ws) {\n      this.ws.close();\n      this.ws = null;\n      this.isConnected = false;\n    }\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"usage-example",children:"Usage Example"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"// Create real-time audio client\nconst rtAudio = new ConduitRealTimeAudio('condt_your_virtual_key');\n\n// Override message handlers\nrtAudio.onTextMessage = (message) => {\n  console.log('Provider message:', message);\n  // Handle provider-specific messages\n};\n\nrtAudio.onAudioData = (audioBuffer) => {\n  console.log('Received audio:', audioBuffer.length, 'bytes');\n  // Process audio data\n};\n\n// Connect\nrtAudio.connect();\n\n// Send messages (format depends on provider)\nrtAudio.sendText({\n  type: 'configure',\n  config: {\n    // Provider-specific configuration\n  }\n});\n"})}),"\n",(0,o.jsx)(n.h2,{id:"provider-specific-usage",children:"Provider-Specific Usage"}),"\n",(0,o.jsx)(n.h3,{id:"openai-realtime-api",children:"OpenAI Realtime API"}),"\n",(0,o.jsx)(n.p,{children:"When using OpenAI's Realtime API through the proxy:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"const openaiRealtime = new ConduitRealTimeAudio(\n  'condt_your_virtual_key', \n  'gpt-4o-realtime-preview', \n  'openai'\n);\n\nopenaiRealtime.onTextMessage = (message) => {\n  // Handle OpenAI Realtime API events\n  switch (message.type) {\n    case 'session.created':\n      console.log('Session created:', message.session);\n      break;\n    case 'conversation.item.input_audio_transcription.completed':\n      console.log('Transcription:', message.transcript);\n      break;\n    case 'response.audio.delta':\n      console.log('Audio response chunk received');\n      break;\n    // Handle other OpenAI events...\n  }\n};\n\nopenaiRealtime.connect();\n\n// Send OpenAI-format messages\nopenaiRealtime.sendText({\n  type: 'session.update',\n  session: {\n    model: 'gpt-4o-realtime-preview',\n    modalities: ['text', 'audio'],\n    voice: 'alloy'\n  }\n});\n"})}),"\n",(0,o.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,o.jsx)(n.h3,{id:"connection-errors",children:"Connection Errors"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"class ResilientRealTimeAudio extends ConduitRealTimeAudio {\n  constructor(apiKey, model, provider, options = {}) {\n    super(apiKey, model, provider);\n    this.reconnectAttempts = 0;\n    this.maxReconnectAttempts = options.maxReconnectAttempts || 5;\n    this.reconnectDelay = options.reconnectDelay || 1000;\n  }\n\n  connect() {\n    super.connect();\n\n    this.ws.on('close', (code, reason) => {\n      console.log(`Connection closed: ${code} ${reason}`);\n      this.isConnected = false;\n      \n      if (this.shouldReconnect(code)) {\n        this.attemptReconnect();\n      }\n    });\n\n    this.ws.on('error', (error) => {\n      console.error('WebSocket error:', error);\n      if (!this.isConnected) {\n        this.attemptReconnect();\n      }\n    });\n  }\n\n  shouldReconnect(closeCode) {\n    // Don't reconnect for auth errors or intentional closes\n    return closeCode !== 1000 && closeCode !== 1002 && closeCode !== 4001;\n  }\n\n  attemptReconnect() {\n    if (this.reconnectAttempts >= this.maxReconnectAttempts) {\n      console.error('Max reconnection attempts reached');\n      return;\n    }\n\n    this.reconnectAttempts++;\n    const delay = this.reconnectDelay * Math.pow(2, this.reconnectAttempts - 1);\n    \n    console.log(`Attempting reconnection ${this.reconnectAttempts}/${this.maxReconnectAttempts} in ${delay}ms`);\n    \n    setTimeout(() => {\n      this.connect();\n    }, delay);\n  }\n\n  onConnectionSuccess() {\n    this.reconnectAttempts = 0;\n    console.log('Reconnection successful');\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"message-validation",children:"Message Validation"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"class ValidatedRealTimeAudio extends ConduitRealTimeAudio {\n  sendText(message) {\n    if (!this.validateMessage(message)) {\n      console.error('Invalid message format:', message);\n      return;\n    }\n    super.sendText(message);\n  }\n\n  validateMessage(message) {\n    if (typeof message !== 'object' || message === null) {\n      return false;\n    }\n\n    if (!message.type || typeof message.type !== 'string') {\n      return false;\n    }\n\n    // Add provider-specific validation\n    return true;\n  }\n\n  handleMessage(data) {\n    try {\n      super.handleMessage(data);\n    } catch (error) {\n      console.error('Message handling error:', error);\n      // Don't crash the connection on message errors\n    }\n  }\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"monitoring-and-debugging",children:"Monitoring and Debugging"}),"\n",(0,o.jsx)(n.h3,{id:"connection-monitoring",children:"Connection Monitoring"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-javascript",children:"class MonitoredRealTimeAudio extends ConduitRealTimeAudio {\n  constructor(apiKey, model, provider) {\n    super(apiKey, model, provider);\n    this.connectionStats = {\n      messagesReceived: 0,\n      messagesSent: 0,\n      bytesReceived: 0,\n      bytesSent: 0,\n      connectionTime: null,\n      lastActivity: null\n    };\n  }\n\n  connect() {\n    this.connectionStats.connectionTime = Date.now();\n    super.connect();\n  }\n\n  handleMessage(data) {\n    this.connectionStats.messagesReceived++;\n    this.connectionStats.lastActivity = Date.now();\n    \n    if (data instanceof Buffer) {\n      this.connectionStats.bytesReceived += data.length;\n    }\n    \n    super.handleMessage(data);\n  }\n\n  send(data) {\n    this.connectionStats.messagesSent++;\n    this.connectionStats.lastActivity = Date.now();\n    \n    if (data instanceof Buffer) {\n      this.connectionStats.bytesSent += data.length;\n    }\n    \n    super.send(data);\n  }\n\n  getStats() {\n    const now = Date.now();\n    return {\n      ...this.connectionStats,\n      connectionDuration: this.connectionStats.connectionTime ? now - this.connectionStats.connectionTime : 0,\n      timeSinceLastActivity: this.connectionStats.lastActivity ? now - this.connectionStats.lastActivity : null,\n      isHealthy: this.isConnected && (now - (this.connectionStats.lastActivity || now)) < 30000\n    };\n  }\n}\n\n// Usage\nconst monitored = new MonitoredRealTimeAudio('condt_your_virtual_key');\nmonitored.connect();\n\n// Check stats periodically\nsetInterval(() => {\n  console.log('Connection stats:', monitored.getStats());\n}, 10000);\n"})}),"\n",(0,o.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,o.jsx)(n.h3,{id:"current-implementation",children:"Current Implementation"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Proxy only"}),": Conduit acts as a WebSocket proxy, not a full implementation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Provider-dependent"}),": Features depend on the underlying provider's WebSocket API"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"No session management"}),": Session state is maintained by the provider, not Conduit"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Limited routing"}),": Basic model/provider routing, no advanced load balancing"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Handle disconnections"}),": Implement reconnection logic for production use"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Validate messages"}),": Check message formats before sending"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Monitor connections"}),": Track connection health and performance"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Error recovery"}),": Implement graceful error handling"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Rate limiting"}),": Respect provider rate limits and connection limits"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Speech-to-Text"}),": Use ",(0,o.jsx)(n.a,{href:"speech-to-text",children:"transcription services"})," for audio processing"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Text-to-Speech"}),": Implement ",(0,o.jsx)(n.a,{href:"text-to-speech",children:"voice synthesis"})," for responses"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Audio Providers"}),": Learn about ",(0,o.jsx)(n.a,{href:"providers",children:"available providers"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Integration Examples"}),": See complete ",(0,o.jsx)(n.a,{href:"../clients/overview",children:"client patterns"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);