"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6096],{1298:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"core-apis/overview","title":"Core APIs Overview","description":"Comprehensive guide to Conduit\'s Core APIs for developers integrating LLM capabilities","source":"@site/docs/core-apis/overview.md","sourceDirName":"core-apis","slug":"/core-apis/overview","permalink":"/Conduit/docs/core-apis/overview","draft":false,"unlisted":false,"editUrl":"https://github.com/knnlabs/Conduit/tree/main/website/docs/core-apis/overview.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Core APIs Overview","description":"Comprehensive guide to Conduit\'s Core APIs for developers integrating LLM capabilities"},"sidebar":"docsSidebar","previous":{"title":"Introduction","permalink":"/Conduit/docs/intro"},"next":{"title":"Text-to-Speech","permalink":"/Conduit/docs/audio/text-to-speech"}}');var r=i(4848),t=i(8453);const o={sidebar_position:1,title:"Core APIs Overview",description:"Comprehensive guide to Conduit's Core APIs for developers integrating LLM capabilities"},a="Core APIs Overview",l={},c=[{value:"API Architecture",id:"api-architecture",level:2},{value:"OpenAI Compatibility",id:"openai-compatibility",level:3},{value:"Unified Provider Access",id:"unified-provider-access",level:3},{value:"Base URLs and Endpoints",id:"base-urls-and-endpoints",level:2},{value:"Environment URLs",id:"environment-urls",level:3},{value:"Available Endpoints",id:"available-endpoints",level:3},{value:"Authentication",id:"authentication",level:2},{value:"Virtual Key Authentication",id:"virtual-key-authentication",level:3},{value:"Request Headers",id:"request-headers",level:3},{value:"Core Endpoints",id:"core-endpoints",level:2},{value:"Chat Completions",id:"chat-completions",level:3},{value:"Embeddings",id:"embeddings",level:3},{value:"Models",id:"models",level:3},{value:"Advanced Features",id:"advanced-features",level:2},{value:"Streaming Responses",id:"streaming-responses",level:3},{value:"Function Calling",id:"function-calling",level:3},{value:"Multimodal Support",id:"multimodal-support",level:3},{value:"Provider Routing",id:"provider-routing",level:2},{value:"Automatic Model Routing",id:"automatic-model-routing",level:3},{value:"Provider Selection",id:"provider-selection",level:3},{value:"Fallback Handling",id:"fallback-handling",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Standard Error Responses",id:"standard-error-responses",level:3},{value:"Error Types",id:"error-types",level:3},{value:"Error Handling Examples",id:"error-handling-examples",level:3},{value:"Rate Limiting",id:"rate-limiting",level:2},{value:"Rate Limit Headers",id:"rate-limit-headers",level:3},{value:"Handling Rate Limits",id:"handling-rate-limits",level:3},{value:"Request/Response Examples",id:"requestresponse-examples",level:2},{value:"Basic Chat Completion",id:"basic-chat-completion",level:3},{value:"Function Calling Response",id:"function-calling-response",level:3},{value:"Client Libraries",id:"client-libraries",level:2},{value:".NET Client",id:"net-client",level:3},{value:"Using OpenAI Libraries",id:"using-openai-libraries",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Connection Pooling",id:"connection-pooling",level:3},{value:"Caching Responses",id:"caching-responses",level:3},{value:"Batch Processing",id:"batch-processing",level:3},{value:"Security Best Practices",id:"security-best-practices",level:2},{value:"API Key Security",id:"api-key-security",level:3},{value:"Request Validation",id:"request-validation",level:3},{value:"Monitoring and Debugging",id:"monitoring-and-debugging",level:2},{value:"Request IDs",id:"request-ids",level:3},{value:"Usage Tracking",id:"usage-tracking",level:3},{value:"Migration from OpenAI",id:"migration-from-openai",level:2},{value:"Minimal Changes Required",id:"minimal-changes-required",level:3},{value:"Provider-Specific Features",id:"provider-specific-features",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"core-apis-overview",children:"Core APIs Overview"})}),"\n",(0,r.jsx)(n.p,{children:"The Conduit Core APIs provide a unified, OpenAI-compatible interface for accessing multiple LLM providers. This guide covers all available endpoints, authentication, request/response formats, and integration patterns for developers."}),"\n",(0,r.jsx)(n.h2,{id:"api-architecture",children:"API Architecture"}),"\n",(0,r.jsx)(n.h3,{id:"openai-compatibility",children:"OpenAI Compatibility"}),"\n",(0,r.jsx)(n.p,{children:"Conduit implements OpenAI's API specification, allowing you to use existing OpenAI client libraries and code with minimal changes:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Standard OpenAI client works with Conduit\nconst openai = new OpenAI({\n  apiKey: 'condt_your_virtual_key',\n  baseURL: 'https://api.conduit.yourdomain.com/v1'\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"unified-provider-access",children:"Unified Provider Access"}),"\n",(0,r.jsx)(n.p,{children:"Behind the scenes, Conduit routes requests to appropriate providers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Client Request \u2192 Virtual Key Auth \u2192 Model Routing \u2192 Provider Selection \u2192 LLM Provider\n                                                                      \u2193\nResponse \u2190  Response Processing \u2190  Provider Response \u2190  Provider API\n"})}),"\n",(0,r.jsx)(n.h2,{id:"base-urls-and-endpoints",children:"Base URLs and Endpoints"}),"\n",(0,r.jsx)(n.h3,{id:"environment-urls",children:"Environment URLs"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Development:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Core API: http://localhost:5000\nBase URL: http://localhost:5000/v1\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Production:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Core API: https://api.conduit.yourdomain.com\nBase URL: https://api.conduit.yourdomain.com/v1\n"})}),"\n",(0,r.jsx)(n.h3,{id:"available-endpoints",children:"Available Endpoints"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Category"}),(0,r.jsx)(n.th,{children:"Endpoint"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Chat"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/chat/completions"})}),(0,r.jsx)(n.td,{children:"Text generation and conversation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Completions"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/completions"})}),(0,r.jsx)(n.td,{children:"Legacy text completion (returns 501 not implemented)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Embeddings"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/embeddings"})}),(0,r.jsx)(n.td,{children:"Vector embeddings generation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Models"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/models"})}),(0,r.jsx)(n.td,{children:"Available models listing"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Audio"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/audio/transcriptions"})}),(0,r.jsx)(n.td,{children:"Speech-to-text transcription"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Audio"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/audio/speech"})}),(0,r.jsx)(n.td,{children:"Text-to-speech synthesis"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Images"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/images/generations"})}),(0,r.jsx)(n.td,{children:"Basic image generation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Real-Time"})}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"/v1/realtime/connect"})}),(0,r.jsx)(n.td,{children:"WebSocket audio proxy"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"authentication",children:"Authentication"}),"\n",(0,r.jsx)(n.h3,{id:"virtual-key-authentication",children:"Virtual Key Authentication"}),"\n",(0,r.jsx)(n.p,{children:"All Core API requests require virtual key authentication:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-http",children:"Authorization: Bearer condt_your_virtual_key_here\n"})}),"\n",(0,r.jsx)(n.h3,{id:"request-headers",children:"Request Headers"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-http",children:"Content-Type: application/json\nAuthorization: Bearer condt_your_virtual_key\nUser-Agent: YourApp/1.0\nX-Request-ID: unique-request-id (optional)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"core-endpoints",children:"Core Endpoints"}),"\n",(0,r.jsx)(n.h3,{id:"chat-completions",children:"Chat Completions"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Primary endpoint for conversational AI:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl https://api.conduit.yourdomain.com/v1/chat/completions \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer condt_your_virtual_key" \\\n  -d \'{\n    "model": "gpt-4",\n    "messages": [\n      {\n        "role": "system",\n        "content": "You are a helpful assistant."\n      },\n      {\n        "role": "user", \n        "content": "Explain quantum computing in simple terms."\n      }\n    ],\n    "max_tokens": 1000,\n    "temperature": 0.7,\n    "stream": false\n  }\'\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Supported Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model"})," (required): Model identifier"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"messages"})," (required): Conversation history"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"max_tokens"}),": Maximum response length"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"temperature"}),": Response randomness (0.0-2.0)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"top_p"}),": Nucleus sampling parameter"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"frequency_penalty"}),": Reduce repetition"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"presence_penalty"}),": Encourage topic diversity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"stream"}),": Enable streaming responses"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"functions"}),": Function calling definitions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"function_call"}),": Function calling mode"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"tools"}),": Tool definitions (newer format)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"tool_choice"}),": Tool selection strategy"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"embeddings",children:"Embeddings"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Generate vector embeddings for text:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl https://api.conduit.yourdomain.com/v1/embeddings \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer condt_your_virtual_key" \\\n  -d \'{\n    "model": "text-embedding-3-large",\n    "input": [\n      "The quick brown fox jumps over the lazy dog.",\n      "Machine learning is a subset of artificial intelligence."\n    ],\n    "encoding_format": "float",\n    "dimensions": 1536\n  }\'\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Supported Parameters:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model"})," (required): Embedding model"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"input"})," (required): Text or array of texts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"encoding_format"}),': "float" or "base64"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"dimensions"}),": Output dimensions (model-dependent)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"user"}),": User identifier for tracking"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"models",children:"Models"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"List available models:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl https://api.conduit.yourdomain.com/v1/models \\\n  -H "Authorization: Bearer condt_your_virtual_key"\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "object": "list",\n  "data": [\n    {\n      "id": "gpt-4",\n      "object": "model",\n      "created": 1677610602,\n      "owned_by": "openai",\n      "provider": "openai",\n      "capabilities": ["chat", "function_calling"],\n      "context_length": 8192,\n      "max_output_tokens": 4096,\n      "pricing": {\n        "input_tokens_per_1k": 0.03,\n        "output_tokens_per_1k": 0.06\n      }\n    }\n  ]\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"advanced-features",children:"Advanced Features"}),"\n",(0,r.jsx)(n.h3,{id:"streaming-responses",children:"Streaming Responses"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Real-time response streaming:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"const stream = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [{role: 'user', content: 'Tell me a story'}],\n  stream: true\n});\n\nfor await (const chunk of stream) {\n  process.stdout.write(chunk.choices[0]?.delta?.content || '');\n}\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Streaming Response Format:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}\n\ndata: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-4","choices":[{"index":0,"delta":{"content":" there"},"finish_reason":null}]}\n\ndata: [DONE]\n'})}),"\n",(0,r.jsx)(n.h3,{id:"function-calling",children:"Function Calling"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Enable AI to call functions:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"const completion = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [{\n    role: 'user',\n    content: 'What is the weather like in Boston?'\n  }],\n  functions: [\n    {\n      name: 'get_current_weather',\n      description: 'Get the current weather in a given location',\n      parameters: {\n        type: 'object',\n        properties: {\n          location: {\n            type: 'string',\n            description: 'The city and state, e.g. San Francisco, CA'\n          },\n          unit: {\n            type: 'string',\n            enum: ['celsius', 'fahrenheit']\n          }\n        },\n        required: ['location']\n      }\n    }\n  ],\n  function_call: 'auto'\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"multimodal-support",children:"Multimodal Support"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Send images with text:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"const completion = await openai.chat.completions.create({\n  model: 'gpt-4-vision-preview',\n  messages: [\n    {\n      role: 'user',\n      content: [\n        {\n          type: 'text',\n          text: 'What is in this image?'\n        },\n        {\n          type: 'image_url',\n          image_url: {\n            url: 'https://example.com/image.jpg'\n          }\n        }\n      ]\n    }\n  ],\n  max_tokens: 1000\n});\n"})}),"\n",(0,r.jsx)(n.h2,{id:"provider-routing",children:"Provider Routing"}),"\n",(0,r.jsx)(n.h3,{id:"automatic-model-routing",children:"Automatic Model Routing"}),"\n",(0,r.jsx)(n.p,{children:"Conduit automatically routes requests to appropriate providers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Request for GPT-4 automatically routed to OpenAI\nconst gptResponse = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [{role: 'user', content: 'Hello'}]\n});\n\n// Request for Claude automatically routed to Anthropic\nconst claudeResponse = await openai.chat.completions.create({\n  model: 'claude-3-sonnet',\n  messages: [{role: 'user', content: 'Hello'}]\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"provider-selection",children:"Provider Selection"}),"\n",(0,r.jsx)(n.p,{children:"Provider selection is handled automatically based on the model name and available provider configurations."}),"\n",(0,r.jsx)(n.h3,{id:"fallback-handling",children:"Fallback Handling"}),"\n",(0,r.jsx)(n.p,{children:"Conduit automatically handles provider failures:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Primary Provider"}),": Attempt request with preferred provider"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Health Check"}),": Verify provider availability"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fallback"}),": Route to backup provider if primary fails"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Response"}),": Return successful response or error"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,r.jsx)(n.h3,{id:"standard-error-responses",children:"Standard Error Responses"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "error": {\n    "message": "The model \'invalid-model\' does not exist",\n    "type": "invalid_request_error",\n    "param": "model",\n    "code": "model_not_found"\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"error-types",children:"Error Types"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Error Type"}),(0,r.jsx)(n.th,{children:"HTTP Status"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"invalid_request_error"})}),(0,r.jsx)(n.td,{children:"400"}),(0,r.jsx)(n.td,{children:"Malformed request"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"authentication_error"})}),(0,r.jsx)(n.td,{children:"401"}),(0,r.jsx)(n.td,{children:"Invalid API key"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"permission_error"})}),(0,r.jsx)(n.td,{children:"403"}),(0,r.jsx)(n.td,{children:"Insufficient permissions"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"not_found_error"})}),(0,r.jsx)(n.td,{children:"404"}),(0,r.jsx)(n.td,{children:"Resource not found"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"rate_limit_error"})}),(0,r.jsx)(n.td,{children:"429"}),(0,r.jsx)(n.td,{children:"Rate limit exceeded"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"api_error"})}),(0,r.jsx)(n.td,{children:"500"}),(0,r.jsx)(n.td,{children:"Internal server error"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"overloaded_error"})}),(0,r.jsx)(n.td,{children:"503"}),(0,r.jsx)(n.td,{children:"Service temporarily unavailable"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"error-handling-examples",children:"Error Handling Examples"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"try {\n  const completion = await openai.chat.completions.create({\n    model: 'gpt-4',\n    messages: [{role: 'user', content: 'Hello'}]\n  });\n} catch (error) {\n  if (error.status === 429) {\n    // Handle rate limiting\n    console.log('Rate limited, retrying in', error.headers['retry-after'], 'seconds');\n  } else if (error.status === 401) {\n    // Handle authentication error\n    console.log('Invalid API key');\n  } else {\n    // Handle other errors\n    console.log('API error:', error.message);\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"rate-limiting",children:"Rate Limiting"}),"\n",(0,r.jsx)(n.h3,{id:"rate-limit-headers",children:"Rate Limit Headers"}),"\n",(0,r.jsx)(n.p,{children:"Responses include rate limiting information:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-http",children:"X-RateLimit-Limit-Requests: 1000\nX-RateLimit-Remaining-Requests: 999\nX-RateLimit-Reset-Requests: 1642267800\nX-RateLimit-Limit-Tokens: 100000\nX-RateLimit-Remaining-Tokens: 95000\nX-RateLimit-Reset-Tokens: 1642267800\n"})}),"\n",(0,r.jsx)(n.h3,{id:"handling-rate-limits",children:"Handling Rate Limits"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"class ConduitClient {\n  async makeRequest(requestFn) {\n    try {\n      return await requestFn();\n    } catch (error) {\n      if (error.status === 429) {\n        const retryAfter = parseInt(error.headers['retry-after'] || '60');\n        console.log(`Rate limited, waiting ${retryAfter} seconds`);\n        await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));\n        return await requestFn(); // Retry once\n      }\n      throw error;\n    }\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"requestresponse-examples",children:"Request/Response Examples"}),"\n",(0,r.jsx)(n.h3,{id:"basic-chat-completion",children:"Basic Chat Completion"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Request:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "model": "gpt-3.5-turbo",\n  "messages": [\n    {"role": "user", "content": "Hello, how are you?"}\n  ]\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "id": "chatcmpl-abc123",\n  "object": "chat.completion",\n  "created": 1677652288,\n  "model": "gpt-3.5-turbo",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": "Hello! I\'m doing well, thank you for asking. How can I help you today?"\n      },\n      "finish_reason": "stop"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 12,\n    "completion_tokens": 19,\n    "total_tokens": 31\n  },\n  "conduit_metadata": {\n    "provider": "openai",\n    "model_version": "gpt-3.5-turbo-0125",\n    "virtual_key_id": "550e8400-e29b-41d4-a716-446655440000",\n    "request_id": "req-abc123",\n    "processing_time_ms": 1234,\n    "cost": 0.0000465\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h3,{id:"function-calling-response",children:"Function Calling Response"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Response with Function Call:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "id": "chatcmpl-def456",\n  "object": "chat.completion",\n  "created": 1677652288,\n  "model": "gpt-4",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": null,\n        "function_call": {\n          "name": "get_current_weather",\n          "arguments": "{\\"location\\": \\"Boston, MA\\"}"\n        }\n      },\n      "finish_reason": "function_call"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 82,\n    "completion_tokens": 18,\n    "total_tokens": 100\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"client-libraries",children:"Client Libraries"}),"\n",(0,r.jsx)(n.h3,{id:"net-client",children:".NET Client"}),"\n",(0,r.jsxs)(n.p,{children:["The repository includes a .NET client in ",(0,r.jsx)(n.code,{children:"/Clients/DotNet/"}),". You can reference it in your projects:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-csharp",children:'using ConduitLLM.Client;\n\nvar client = new ConduitClient("condt_your_virtual_key", "https://api.conduit.yourdomain.com");\n\nvar response = await client.ChatCompletions.CreateAsync(new ChatCompletionRequest\n{\n    Model = "gpt-4",\n    Messages = new[] { new Message { Role = "user", Content = "Hello" } }\n});\n'})}),"\n",(0,r.jsx)(n.h3,{id:"using-openai-libraries",children:"Using OpenAI Libraries"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Python with OpenAI library:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from openai import OpenAI\n\nclient = OpenAI(\n    api_key="condt_your_virtual_key",\n    base_url="https://api.conduit.yourdomain.com/v1"\n)\n\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    messages=[{"role": "user", "content": "Hello"}]\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"JavaScript with OpenAI library:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"import OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: 'condt_your_virtual_key',\n  baseURL: 'https://api.conduit.yourdomain.com/v1'\n});\n\nconst completion = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [{role: 'user', content: 'Hello'}]\n});\n"})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"connection-pooling",children:"Connection Pooling"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Reuse client instances for connection pooling\nconst openai = new OpenAI({\n  apiKey: 'condt_your_virtual_key',\n  baseURL: 'https://api.conduit.yourdomain.com/v1',\n  httpAgent: new https.Agent({\n    keepAlive: true,\n    maxSockets: 20\n  })\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"caching-responses",children:"Caching Responses"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"class CachedConduitClient {\n  constructor(client) {\n    this.client = client;\n    this.cache = new Map();\n  }\n\n  async getCachedCompletion(params) {\n    const cacheKey = JSON.stringify(params);\n    \n    if (this.cache.has(cacheKey)) {\n      return this.cache.get(cacheKey);\n    }\n\n    const response = await this.client.chat.completions.create(params);\n    this.cache.set(cacheKey, response);\n    \n    return response;\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h3,{id:"batch-processing",children:"Batch Processing"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"async function processBatch(prompts) {\n  const promises = prompts.map(prompt => \n    openai.chat.completions.create({\n      model: 'gpt-3.5-turbo',\n      messages: [{role: 'user', content: prompt}]\n    })\n  );\n\n  try {\n    const results = await Promise.allSettled(promises);\n    return results.map((result, index) => ({\n      prompt: prompts[index],\n      success: result.status === 'fulfilled',\n      response: result.status === 'fulfilled' ? result.value : null,\n      error: result.status === 'rejected' ? result.reason : null\n    }));\n  } catch (error) {\n    console.error('Batch processing failed:', error);\n    throw error;\n  }\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"security-best-practices",children:"Security Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"api-key-security",children:"API Key Security"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Environment Variables"}),": Store keys in environment variables"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Key Rotation"}),": Rotate virtual keys regularly"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Scope Limitation"}),": Use keys with minimal required permissions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitoring"}),": Monitor key usage for anomalies"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Good: Use environment variables\nconst client = new OpenAI({\n  apiKey: process.env.CONDUIT_API_KEY,\n  baseURL: process.env.CONDUIT_BASE_URL\n});\n\n// Bad: Hardcoded keys\nconst client = new OpenAI({\n  apiKey: 'condt_hardcoded_key_here' // Never do this!\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"request-validation",children:"Request Validation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"function validateChatRequest(params) {\n  if (!params.model) {\n    throw new Error('Model is required');\n  }\n  \n  if (!params.messages || !Array.isArray(params.messages)) {\n    throw new Error('Messages must be an array');\n  }\n  \n  if (params.max_tokens && params.max_tokens > 4096) {\n    throw new Error('max_tokens cannot exceed 4096');\n  }\n  \n  return true;\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"monitoring-and-debugging",children:"Monitoring and Debugging"}),"\n",(0,r.jsx)(n.h3,{id:"request-ids",children:"Request IDs"}),"\n",(0,r.jsx)(n.p,{children:"Track requests using correlation IDs:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"const response = await openai.chat.completions.create({\n  model: 'gpt-4',\n  messages: [{role: 'user', content: 'Hello'}]\n}, {\n  headers: {\n    'X-Request-ID': 'req-' + Date.now()\n  }\n});\n\nconsole.log('Request ID:', response.conduit_metadata?.request_id);\n"})}),"\n",(0,r.jsx)(n.h3,{id:"usage-tracking",children:"Usage Tracking"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"function logUsage(response) {\n  const metadata = response.conduit_metadata;\n  console.log({\n    requestId: metadata?.request_id,\n    model: response.model,\n    provider: metadata?.provider,\n    tokensUsed: response.usage?.total_tokens,\n    cost: metadata?.cost,\n    processingTime: metadata?.processing_time_ms\n  });\n}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"migration-from-openai",children:"Migration from OpenAI"}),"\n",(0,r.jsx)(n.h3,{id:"minimal-changes-required",children:"Minimal Changes Required"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Before (OpenAI direct):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"const openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY\n});\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"After (Conduit):"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"const openai = new OpenAI({\n  apiKey: process.env.CONDUIT_VIRTUAL_KEY,\n  baseURL: 'https://api.conduit.yourdomain.com/v1'\n});\n"})}),"\n",(0,r.jsx)(n.h3,{id:"provider-specific-features",children:"Provider-Specific Features"}),"\n",(0,r.jsx)(n.p,{children:"Some provider-specific features may require adjustments:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:"// Anthropic-specific features through Conduit\nconst response = await openai.chat.completions.create({\n  model: 'claude-3-sonnet',\n  messages: [{role: 'user', content: 'Hello'}],\n  // Anthropic-specific parameters\n  anthropic_version: '2023-06-01',\n  stop_sequences: ['\\n\\nHuman:']\n});\n"})}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Text-to-Speech"}),": Explore ",(0,r.jsx)(n.a,{href:"../audio/text-to-speech",children:"text-to-speech capabilities"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-Time Audio"}),": Learn about ",(0,r.jsx)(n.a,{href:"../audio/real-time-audio",children:"real-time audio streaming"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Media Generation"}),": Discover ",(0,r.jsx)(n.a,{href:"../media/image-generation",children:"image and video generation"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Administration"}),": Manage your setup via ",(0,r.jsx)(n.a,{href:"../admin/admin-api-overview",children:"Admin API"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const r={},t=s.createContext(r);function o(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);