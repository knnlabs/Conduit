"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8108],{7604:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"deployment/scaling-configuration","title":"Scaling Configuration","description":"Configure Conduit for horizontal and vertical scaling to handle high-throughput workloads","source":"@site/docs/deployment/scaling-configuration.md","sourceDirName":"deployment","slug":"/deployment/scaling-configuration","permalink":"/Conduit/docs/deployment/scaling-configuration","draft":false,"unlisted":false,"editUrl":"https://github.com/knnlabs/Conduit/tree/main/website/docs/deployment/scaling-configuration.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Scaling Configuration","description":"Configure Conduit for horizontal and vertical scaling to handle high-throughput workloads"}}');var t=i(4848),r=i(8453);const s={sidebar_position:3,title:"Scaling Configuration",description:"Configure Conduit for horizontal and vertical scaling to handle high-throughput workloads"},o="Scaling Configuration",l={},c=[{value:"Scaling Overview",id:"scaling-overview",level:2},{value:"Performance Targets",id:"performance-targets",level:2},{value:"Horizontal Scaling Configuration",id:"horizontal-scaling-configuration",level:2},{value:"Core API Scaling",id:"core-api-scaling",level:3},{value:"Admin API Scaling",id:"admin-api-scaling",level:3},{value:"Load Balancer Configuration",id:"load-balancer-configuration",level:3},{value:"Vertical Scaling Configuration",id:"vertical-scaling-configuration",level:2},{value:"Resource Allocation",id:"resource-allocation",level:3},{value:"JVM/Runtime Optimization",id:"jvmruntime-optimization",level:3},{value:"Database Scaling",id:"database-scaling",level:2},{value:"Connection Pool Configuration",id:"connection-pool-configuration",level:3},{value:"PostgreSQL Scaling Configuration",id:"postgresql-scaling-configuration",level:3},{value:"Read Replica Configuration",id:"read-replica-configuration",level:3},{value:"Redis Scaling",id:"redis-scaling",level:2},{value:"Redis Cluster Configuration",id:"redis-cluster-configuration",level:3},{value:"Cache Configuration for Scale",id:"cache-configuration-for-scale",level:3},{value:"RabbitMQ Scaling",id:"rabbitmq-scaling",level:2},{value:"High-Throughput RabbitMQ Configuration",id:"high-throughput-rabbitmq-configuration",level:3},{value:"RabbitMQ Cluster Configuration",id:"rabbitmq-cluster-configuration",level:3},{value:"HTTP Client Scaling",id:"http-client-scaling",level:2},{value:"Connection Pool Optimization",id:"connection-pool-optimization",level:3},{value:"Provider-Specific Scaling",id:"provider-specific-scaling",level:3},{value:"Auto-Scaling Triggers",id:"auto-scaling-triggers",level:2},{value:"Custom Metrics Auto-Scaling",id:"custom-metrics-auto-scaling",level:3},{value:"KEDA Auto-Scaling",id:"keda-auto-scaling",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Application-Level Optimizations",id:"application-level-optimizations",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Monitoring Scaled Deployments",id:"monitoring-scaled-deployments",level:2},{value:"Scaling Metrics",id:"scaling-metrics",level:3},{value:"Scaling Alerts",id:"scaling-alerts",level:3},{value:"Capacity Planning",id:"capacity-planning",level:2},{value:"Resource Planning Matrix",id:"resource-planning-matrix",level:3},{value:"Growth Planning",id:"growth-planning",level:3},{value:"Troubleshooting Scaling Issues",id:"troubleshooting-scaling-issues",level:2},{value:"Common Scaling Problems",id:"common-scaling-problems",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Scaling Strategy",id:"scaling-strategy",level:3},{value:"Resource Management",id:"resource-management",level:3},{value:"Operational Excellence",id:"operational-excellence",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"scaling-configuration",children:"Scaling Configuration"})}),"\n",(0,t.jsx)(e.p,{children:"This guide covers scaling Conduit to handle high-throughput workloads, from hundreds to thousands of requests per minute, with horizontal and vertical scaling strategies."}),"\n",(0,t.jsx)(e.h2,{id:"scaling-overview",children:"Scaling Overview"}),"\n",(0,t.jsx)(e.p,{children:"Conduit supports multiple scaling approaches:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Vertical Scaling"}),": Increase resources for existing instances"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Horizontal Scaling"}),": Add more service instances"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Database Scaling"}),": Connection pooling and read replicas"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Event Bus Scaling"}),": RabbitMQ clustering and partitioning"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Cache Scaling"}),": Redis clustering and optimization"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"performance-targets",children:"Performance Targets"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Throughput Level"}),(0,t.jsx)(e.th,{children:"Requests/Minute"}),(0,t.jsx)(e.th,{children:"Scaling Strategy"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Small"})}),(0,t.jsx)(e.td,{children:"< 100"}),(0,t.jsx)(e.td,{children:"Single instance"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Medium"})}),(0,t.jsx)(e.td,{children:"100-1,000"}),(0,t.jsx)(e.td,{children:"Vertical scaling"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Large"})}),(0,t.jsx)(e.td,{children:"1,000-10,000"}),(0,t.jsx)(e.td,{children:"Horizontal scaling"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Enterprise"})}),(0,t.jsx)(e.td,{children:"10,000+"}),(0,t.jsx)(e.td,{children:"Full clustering"})]})]})]}),"\n",(0,t.jsx)(e.h2,{id:"horizontal-scaling-configuration",children:"Horizontal Scaling Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"core-api-scaling",children:"Core API Scaling"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# kubernetes/core-api-hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: conduit-core-api-hpa\n  namespace: conduit-production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: conduit-core-api\n  minReplicas: 3\n  maxReplicas: 20\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  - type: Pods\n    pods:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: AverageValue\n        averageValue: "100"\n  behavior:\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 25\n        periodSeconds: 60\n'})}),"\n",(0,t.jsx)(e.h3,{id:"admin-api-scaling",children:"Admin API Scaling"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:"# kubernetes/admin-api-hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: conduit-admin-api-hpa\n  namespace: conduit-production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: conduit-admin-api\n  minReplicas: 2\n  maxReplicas: 5\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n"})}),"\n",(0,t.jsx)(e.h3,{id:"load-balancer-configuration",children:"Load Balancer Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-nginx",children:'# nginx-scaled.conf\nupstream conduit_core_api {\n    least_conn;\n    \n    # Primary instances\n    server conduit-core-api-1:5000 max_fails=3 fail_timeout=30s weight=10;\n    server conduit-core-api-2:5000 max_fails=3 fail_timeout=30s weight=10;\n    server conduit-core-api-3:5000 max_fails=3 fail_timeout=30s weight=10;\n    \n    # Auto-scaled instances (added/removed dynamically)\n    server conduit-core-api-4:5000 max_fails=3 fail_timeout=30s weight=10 backup;\n    server conduit-core-api-5:5000 max_fails=3 fail_timeout=30s weight=10 backup;\n    \n    # Connection settings for high throughput\n    keepalive 32;\n    keepalive_requests 1000;\n    keepalive_timeout 60s;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name api.conduit.yourdomain.com;\n    \n    # Connection limits for scaling\n    limit_conn_zone $binary_remote_addr zone=addr:10m;\n    limit_req_zone $binary_remote_addr zone=api:10m rate=100r/s;\n    \n    location /v1/ {\n        limit_conn addr 10;\n        limit_req zone=api burst=50 nodelay;\n        \n        proxy_pass http://conduit_core_api;\n        proxy_http_version 1.1;\n        proxy_set_header Connection "";\n        \n        # Optimized for high throughput\n        proxy_buffering on;\n        proxy_buffer_size 4k;\n        proxy_buffers 8 4k;\n        proxy_busy_buffers_size 8k;\n        \n        # Connection pooling\n        proxy_socket_keepalive on;\n        proxy_connect_timeout 5s;\n        proxy_send_timeout 10s;\n        proxy_read_timeout 30s;\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"vertical-scaling-configuration",children:"Vertical Scaling Configuration"}),"\n",(0,t.jsx)(e.h3,{id:"resource-allocation",children:"Resource Allocation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# Baseline configuration (100-500 req/min)\nresources:\n  requests:\n    memory: "512Mi"\n    cpu: "500m"\n  limits:\n    memory: "1Gi"\n    cpu: "1000m"\n\n# Medium load configuration (500-2000 req/min)  \nresources:\n  requests:\n    memory: "1Gi"\n    cpu: "1000m"\n  limits:\n    memory: "2Gi"\n    cpu: "2000m"\n\n# High load configuration (2000+ req/min)\nresources:\n  requests:\n    memory: "2Gi"\n    cpu: "2000m"\n  limits:\n    memory: "4Gi"\n    cpu: "4000m"\n'})}),"\n",(0,t.jsx)(e.h3,{id:"jvmruntime-optimization",children:"JVM/Runtime Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# .NET Runtime optimization for high throughput\nDOTNET_gcServer=1\nDOTNET_gcConcurrent=1\nDOTNET_gcRetainVM=1\nDOTNET_ThreadPool_ForceMinWorkerThreads=100\nDOTNET_ThreadPool_ForceMaxWorkerThreads=1000\n\n# Garbage collection tuning\nDOTNET_GCHeapHardLimit=2147483648  # 2GB heap limit\nDOTNET_GCHighMemPercent=90\nDOTNET_GCConserveMemory=5\n"})}),"\n",(0,t.jsx)(e.h2,{id:"database-scaling",children:"Database Scaling"}),"\n",(0,t.jsx)(e.h3,{id:"connection-pool-configuration",children:"Connection Pool Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# High-throughput database configuration\nCONDUITLLM__DATABASE__MAXPOOLSIZE=200\nCONDUITLLM__DATABASE__MINPOOLSIZE=20\nCONDUITLLM__DATABASE__CONNECTIONTIMEOUT=30\nCONDUITLLM__DATABASE__COMMANDTIMEOUT=30\nCONDUITLLM__DATABASE__CONNECTIONLIFETIME=300\nCONDUITLLM__DATABASE__CONNECTIONIDLETIMEOUT=60\n\n# Database-specific optimizations\nCONDUITLLM__DATABASE__INCLUDEERRORDETAIL=false\nCONDUITLLM__DATABASE__ENABLESERVICEPROVIDERVALIDATION=false\nCONDUITLLM__DATABASE__ENABLESENSITIVEDATALOGGING=false\n"})}),"\n",(0,t.jsx)(e.h3,{id:"postgresql-scaling-configuration",children:"PostgreSQL Scaling Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-sql",children:"-- PostgreSQL performance tuning for high concurrency\nALTER SYSTEM SET max_connections = 400;\nALTER SYSTEM SET shared_buffers = '512MB';\nALTER SYSTEM SET effective_cache_size = '2GB';\nALTER SYSTEM SET work_mem = '8MB';\nALTER SYSTEM SET maintenance_work_mem = '128MB';\nALTER SYSTEM SET checkpoint_completion_target = 0.9;\nALTER SYSTEM SET wal_buffers = '16MB';\nALTER SYSTEM SET default_statistics_target = 100;\nALTER SYSTEM SET random_page_cost = 1.1;\nALTER SYSTEM SET effective_io_concurrency = 200;\n\n-- Connection and query optimization\nALTER SYSTEM SET log_min_duration_statement = 1000;  -- Log slow queries\nALTER SYSTEM SET log_lock_waits = on;\nALTER SYSTEM SET deadlock_timeout = 1000;\n\nSELECT pg_reload_conf();\n"})}),"\n",(0,t.jsx)(e.h3,{id:"read-replica-configuration",children:"Read Replica Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Read replica for analytics and reporting\nCONDUITLLM__DATABASE__READREPLICA__CONNECTIONSTRING=postgresql://conduit:password@postgres-read:5432/conduit\nCONDUITLLM__DATABASE__READREPLICA__ENABLED=true\nCONDUITLLM__DATABASE__READREPLICA__OPERATIONS=Analytics,Reporting,HealthChecks\n"})}),"\n",(0,t.jsx)(e.h2,{id:"redis-scaling",children:"Redis Scaling"}),"\n",(0,t.jsx)(e.h3,{id:"redis-cluster-configuration",children:"Redis Cluster Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Redis cluster for high availability and scaling\nREDIS_URL=redis://redis-cluster:6379/0\nREDIS_URL_SIGNALR=redis://redis-cluster:6379/2\n\n# Connection pool settings\nCONDUITLLM__REDIS__CONNECTIONSTRING=redis-cluster:6379,abortConnect=false,connectTimeout=5000,syncTimeout=5000,connectRetry=3\nCONDUITLLM__REDIS__COMMANDTIMEOUT=5000\nCONDUITLLM__REDIS__CONNECTTIMEOUT=5000\nCONDUITLLM__REDIS__RETRYDELAY=1000\n\n# Connection pooling\nCONDUITLLM__REDIS__CONNECTIONPOOLSIZE=50\nCONDUITLLM__REDIS__CONNECTIONMULTIPLEXER=true\n"})}),"\n",(0,t.jsx)(e.h3,{id:"cache-configuration-for-scale",children:"Cache Configuration for Scale"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Cache TTL optimization for high throughput\nCONDUITLLM__CACHE__VIRTUALKEY__TTL=300      # 5 minutes\nCONDUITLLM__CACHE__PROVIDER__TTL=3600       # 1 hour  \nCONDUITLLM__CACHE__MODEL__TTL=7200          # 2 hours\nCONDUITLLM__CACHE__NAVIGATION__TTL=300      # 5 minutes\n\n# Cache size limits\nCONDUITLLM__CACHE__MAXMEMORY=1073741824     # 1GB\nCONDUITLLM__CACHE__MAXMEMORYPOLICY=allkeys-lru\nCONDUITLLM__CACHE__MAXENTRIES=1000000       # 1M entries\n"})}),"\n",(0,t.jsx)(e.h2,{id:"rabbitmq-scaling",children:"RabbitMQ Scaling"}),"\n",(0,t.jsx)(e.h3,{id:"high-throughput-rabbitmq-configuration",children:"High-Throughput RabbitMQ Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Core scaling configuration\nCONDUITLLM__RABBITMQ__PREFETCHCOUNT=50           # Increased from 25\nCONDUITLLM__RABBITMQ__PARTITIONCOUNT=50          # Increased from 30  \nCONDUITLLM__RABBITMQ__CONCURRENTMESSAGELIMIT=100 # Increased from 50\n\n# Connection pooling for scale\nCONDUITLLM__RABBITMQ__MAXCONNECTIONS=10          # Increased from 5\nCONDUITLLM__RABBITMQ__MINCONNECTIONS=5           # Increased from 2\nCONDUITLLM__RABBITMQ__CONNECTIONPOOLSIZE=20\n\n# Queue-specific scaling\nCONDUITLLM__RABBITMQ__WEBHOOK__PREFETCHCOUNT=200\nCONDUITLLM__RABBITMQ__WEBHOOK__CONCURRENTMESSAGELIMIT=150\nCONDUITLLM__RABBITMQ__WEBHOOK__BATCHSIZE=200\n\nCONDUITLLM__RABBITMQ__MEDIA__PREFETCHCOUNT=20\nCONDUITLLM__RABBITMQ__MEDIA__CONCURRENTMESSAGELIMIT=10\nCONDUITLLM__RABBITMQ__MEDIA__PARALLELPROCESSING=true\n"})}),"\n",(0,t.jsx)(e.h3,{id:"rabbitmq-cluster-configuration",children:"RabbitMQ Cluster Configuration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# kubernetes/rabbitmq-cluster.yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: rabbitmq-cluster\n  namespace: conduit-production\nspec:\n  serviceName: rabbitmq-cluster\n  replicas: 3\n  selector:\n    matchLabels:\n      app: rabbitmq\n  template:\n    metadata:\n      labels:\n        app: rabbitmq\n    spec:\n      containers:\n      - name: rabbitmq\n        image: rabbitmq:3.12-management\n        env:\n        - name: RABBITMQ_ERLANG_COOKIE\n          value: "conduit-cluster-cookie"\n        - name: RABBITMQ_USE_LONGNAME\n          value: "true"\n        - name: RABBITMQ_NODENAME\n          value: "rabbit@$(HOSTNAME).rabbitmq-cluster.conduit-production.svc.cluster.local"\n        - name: RABBITMQ_DEFAULT_USER\n          value: "conduit"\n        - name: RABBITMQ_DEFAULT_PASS\n          valueFrom:\n            secretKeyRef:\n              name: rabbitmq-secret\n              key: password\n        ports:\n        - containerPort: 5672\n        - containerPort: 15672\n        - containerPort: 25672\n        volumeMounts:\n        - name: rabbitmq-data\n          mountPath: /var/lib/rabbitmq\n        resources:\n          requests:\n            memory: "1Gi"\n            cpu: "500m"\n          limits:\n            memory: "2Gi"\n            cpu: "1000m"\n  volumeClaimTemplates:\n  - metadata:\n      name: rabbitmq-data\n    spec:\n      accessModes: ["ReadWriteOnce"]\n      resources:\n        requests:\n          storage: 20Gi\n'})}),"\n",(0,t.jsx)(e.h2,{id:"http-client-scaling",children:"HTTP Client Scaling"}),"\n",(0,t.jsx)(e.h3,{id:"connection-pool-optimization",children:"Connection Pool Optimization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"// HTTP client configuration for high throughput\nservices.Configure<HttpClientSettings>(options =>\n{\n    options.MaxConnectionsPerServer = 100;      // Increased from 50\n    options.ConnectionLifetime = TimeSpan.FromMinutes(5);\n    options.PooledConnectionIdleTimeout = TimeSpan.FromMinutes(2);\n    options.RequestTimeout = TimeSpan.FromSeconds(30);\n    options.KeepAlivePingDelay = TimeSpan.FromSeconds(30);\n    options.KeepAlivePingTimeout = TimeSpan.FromSeconds(20);\n    options.EnableHttp2 = true;\n    options.Http2MaxStreamsPerConnection = 100;\n});\n"})}),"\n",(0,t.jsx)(e.h3,{id:"provider-specific-scaling",children:"Provider-Specific Scaling"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Provider connection limits\nCONDUITLLM__PROVIDERS__OPENAI__MAXCONNECTIONS=50\nCONDUITLLM__PROVIDERS__ANTHROPIC__MAXCONNECTIONS=30\nCONDUITLLM__PROVIDERS__GOOGLE__MAXCONNECTIONS=40\n\n# Rate limiting per provider\nCONDUITLLM__PROVIDERS__OPENAI__RATELIMIT=1000    # req/min\nCONDUITLLM__PROVIDERS__ANTHROPIC__RATELIMIT=500  # req/min\nCONDUITLLM__PROVIDERS__GOOGLE__RATELIMIT=800     # req/min\n\n# Circuit breaker settings\nCONDUITLLM__CIRCUITBREAKER__FAILURETHRESHOLD=0.1  # 10% failure rate\nCONDUITLLM__CIRCUITBREAKER__TIMEOUT=60000         # 60s timeout\nCONDUITLLM__CIRCUITBREAKER__RETRYDELAY=5000       # 5s retry delay\n"})}),"\n",(0,t.jsx)(e.h2,{id:"auto-scaling-triggers",children:"Auto-Scaling Triggers"}),"\n",(0,t.jsx)(e.h3,{id:"custom-metrics-auto-scaling",children:"Custom Metrics Auto-Scaling"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# kubernetes/custom-metrics-hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: conduit-custom-metrics-hpa\n  namespace: conduit-production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: conduit-core-api\n  minReplicas: 3\n  maxReplicas: 50\n  metrics:\n  - type: External\n    external:\n      metric:\n        name: rabbitmq_queue_messages\n        selector:\n          matchLabels:\n            queue: "conduit.webhook-delivery"\n      target:\n        type: Value\n        value: "500"\n  - type: External\n    external:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: Value\n        value: "100"\n  - type: External\n    external:\n      metric:\n        name: database_connection_pool_utilization\n      target:\n        type: Value\n        value: "70"\n'})}),"\n",(0,t.jsx)(e.h3,{id:"keda-auto-scaling",children:"KEDA Auto-Scaling"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# keda/rabbitmq-scaler.yaml\napiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: conduit-rabbitmq-scaler\n  namespace: conduit-production\nspec:\n  scaleTargetRef:\n    name: conduit-core-api\n  minReplicaCount: 3\n  maxReplicaCount: 20\n  triggers:\n  - type: rabbitmq\n    metadata:\n      host: "amqp://conduit:password@rabbitmq-service:5672/"\n      queueName: "conduit.webhook-delivery"\n      queueLength: "10"\n  - type: prometheus\n    metadata:\n      serverAddress: http://prometheus:9090\n      metricName: http_requests_per_second\n      threshold: "100"\n      query: rate(http_requests_total[1m])\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"application-level-optimizations",children:"Application-Level Optimizations"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"// Startup.cs optimizations for high throughput\npublic void ConfigureServices(IServiceCollection services)\n{\n    // Connection pooling\n    services.Configure<KestrelServerOptions>(options =>\n    {\n        options.Limits.MaxConcurrentConnections = 1000;\n        options.Limits.MaxConcurrentUpgradedConnections = 1000;\n        options.Limits.MaxRequestBodySize = 10 * 1024 * 1024; // 10MB\n        options.Limits.MinRequestBodyDataRate = null;\n        options.Limits.MinResponseDataRate = null;\n    });\n    \n    // Thread pool optimization\n    ThreadPool.SetMinThreads(100, 100);\n    ThreadPool.SetMaxThreads(1000, 1000);\n    \n    // JSON serialization optimization\n    services.Configure<JsonOptions>(options =>\n    {\n        options.SerializerOptions.DefaultBufferSize = 65536;\n    });\n    \n    // HTTP client optimization\n    services.AddHttpClient()\n        .ConfigureHttpClientDefaults(builder =>\n        {\n            builder.UseSocketsHttpHandler()\n                .ConfigureHttpHandlerHttpPool(pool =>\n                {\n                    pool.MaxConnectionsPerServer = 100;\n                    pool.ConnectionLifetime = TimeSpan.FromMinutes(5);\n                });\n        });\n}\n"})}),"\n",(0,t.jsx)(e.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Memory optimization for high throughput\nDOTNET_GCHeapHardLimit=4294967296        # 4GB heap limit\nDOTNET_GCHighMemPercent=85\nDOTNET_GCConserveMemory=5\n\n# Large object heap optimization\nDOTNET_GCLOHThreshold=8192\nDOTNET_GCRetainVM=1\n\n# Server garbage collection\nDOTNET_gcServer=1\nDOTNET_gcConcurrent=1\n"})}),"\n",(0,t.jsx)(e.h2,{id:"monitoring-scaled-deployments",children:"Monitoring Scaled Deployments"}),"\n",(0,t.jsx)(e.h3,{id:"scaling-metrics",children:"Scaling Metrics"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-prometheus",children:'# Auto-scaling metrics\nhpa_current_replicas{hpa="conduit-core-api-hpa"}\nhpa_desired_replicas{hpa="conduit-core-api-hpa"}\nhpa_max_replicas{hpa="conduit-core-api-hpa"}\n\n# Resource utilization\ncontainer_cpu_usage_seconds_total{pod=~"conduit-core-api-.*"}\ncontainer_memory_usage_bytes{pod=~"conduit-core-api-.*"}\n\n# Connection pool metrics\ndatabase_connections_active / database_connections_total\nredis_connections_active / redis_connections_total\n'})}),"\n",(0,t.jsx)(e.h3,{id:"scaling-alerts",children:"Scaling Alerts"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-yaml",children:'# alerts/scaling.yml\ngroups:\n  - name: conduit-scaling\n    rules:\n      - alert: HPAMaxReplicasReached\n        expr: hpa_current_replicas{hpa="conduit-core-api-hpa"} >= hpa_max_replicas{hpa="conduit-core-api-hpa"}\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: "HPA has reached maximum replicas"\n          description: "Auto-scaler cannot scale further - consider increasing max replicas"\n          \n      - alert: ScalingEventsFailed\n        expr: increase(hpa_scaling_events_total{result="failed"}[5m]) > 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: "Auto-scaling events are failing"\n          description: "{{$value}} scaling events have failed in the last 5 minutes"\n'})}),"\n",(0,t.jsx)(e.h2,{id:"capacity-planning",children:"Capacity Planning"}),"\n",(0,t.jsx)(e.h3,{id:"resource-planning-matrix",children:"Resource Planning Matrix"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Load Level"}),(0,t.jsx)(e.th,{children:"Core API Replicas"}),(0,t.jsx)(e.th,{children:"CPU per Pod"}),(0,t.jsx)(e.th,{children:"Memory per Pod"}),(0,t.jsx)(e.th,{children:"Database Connections"}),(0,t.jsx)(e.th,{children:"RabbitMQ Partitions"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.strong,{children:"Low"})," (< 500 req/min)"]}),(0,t.jsx)(e.td,{children:"2-3"}),(0,t.jsx)(e.td,{children:"500m"}),(0,t.jsx)(e.td,{children:"1Gi"}),(0,t.jsx)(e.td,{children:"50"}),(0,t.jsx)(e.td,{children:"10"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.strong,{children:"Medium"})," (500-2000 req/min)"]}),(0,t.jsx)(e.td,{children:"3-5"}),(0,t.jsx)(e.td,{children:"1000m"}),(0,t.jsx)(e.td,{children:"2Gi"}),(0,t.jsx)(e.td,{children:"100"}),(0,t.jsx)(e.td,{children:"20"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.strong,{children:"High"})," (2000-5000 req/min)"]}),(0,t.jsx)(e.td,{children:"5-10"}),(0,t.jsx)(e.td,{children:"2000m"}),(0,t.jsx)(e.td,{children:"4Gi"}),(0,t.jsx)(e.td,{children:"200"}),(0,t.jsx)(e.td,{children:"30"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsxs)(e.td,{children:[(0,t.jsx)(e.strong,{children:"Very High"})," (5000+ req/min)"]}),(0,t.jsx)(e.td,{children:"10-20"}),(0,t.jsx)(e.td,{children:"4000m"}),(0,t.jsx)(e.td,{children:"8Gi"}),(0,t.jsx)(e.td,{children:"400"}),(0,t.jsx)(e.td,{children:"50"})]})]})]}),"\n",(0,t.jsx)(e.h3,{id:"growth-planning",children:"Growth Planning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Scaling decision points\nif req_per_minute > 1000 && cpu_utilization > 70:\n    scale_horizontally()\n    \nif database_connections > 80%:\n    increase_connection_pool()\n    consider_read_replicas()\n    \nif rabbitmq_queue_depth > 1000:\n    increase_consumers()\n    add_partitions()\n    \nif memory_usage > 85%:\n    increase_pod_memory()\n    optimize_cache_settings()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-scaling-issues",children:"Troubleshooting Scaling Issues"}),"\n",(0,t.jsx)(e.h3,{id:"common-scaling-problems",children:"Common Scaling Problems"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Pods Not Scaling:"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Check HPA status\nkubectl describe hpa conduit-core-api-hpa\n\n# Check metrics availability\nkubectl top pods -n conduit-production\n\n# Verify resource requests/limits\nkubectl describe pod conduit-core-api-xxx\n"})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Database Connection Exhaustion:"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Monitor connection usage\nkubectl logs deployment/conduit-core-api | grep -i "connection"\n\n# Check database metrics\ncurl -s http://prometheus:9090/api/v1/query?query=database_connections_active\n'})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"RabbitMQ Queue Buildup:"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Check consumer status\nkubectl exec deployment/rabbitmq -- rabbitmqctl list_consumers\n\n# Monitor queue depths\nkubectl exec deployment/rabbitmq -- rabbitmqctl list_queues name messages\n"})}),"\n",(0,t.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsx)(e.h3,{id:"scaling-strategy",children:"Scaling Strategy"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Start Conservative"}),": Begin with minimum viable scaling configuration"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Monitor Closely"}),": Watch all metrics during scaling events"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Scale Gradually"}),": Avoid sudden large scaling jumps"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Test Scaling"}),": Verify auto-scaling works under load"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Plan Capacity"}),": Monitor growth trends and plan ahead"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"resource-management",children:"Resource Management"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Set Resource Limits"}),": Always define CPU/memory limits"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Use Resource Requests"}),": Ensure scheduler knows requirements"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Monitor Utilization"}),": Track actual vs requested resources"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Optimize Regularly"}),": Review and adjust based on usage patterns"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"operational-excellence",children:"Operational Excellence"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Automate Scaling"}),": Use HPA and KEDA for automatic scaling"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Monitor Performance"}),": Track all scaling-related metrics"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Plan for Failure"}),": Ensure scaling works during incidents"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Document Procedures"}),": Maintain scaling runbooks and procedures"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Production Deployment"}),": Deploy your ",(0,t.jsx)(e.a,{href:"production-deployment",children:"scaled production environment"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Monitoring"}),": Set up ",(0,t.jsx)(e.a,{href:"monitoring-health",children:"comprehensive monitoring"})," for scaled deployments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"RabbitMQ"}),": Configure ",(0,t.jsx)(e.a,{href:"rabbitmq-setup",children:"RabbitMQ clustering"})," for high availability"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Performance Testing"}),": Validate scaling behavior under load"]}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>o});var a=i(6540);const t={},r=a.createContext(t);function s(n){const e=a.useContext(r);return a.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),a.createElement(r.Provider,{value:e},n.children)}}}]);