<Project Sdk="Microsoft.NET.Sdk">

  <ItemGroup>
    <ProjectReference Include="..\ConduitLLM.Core\ConduitLLM.Core.csproj" />
    <ProjectReference Include="..\ConduitLLM.Configuration\ConduitLLM.Configuration.csproj" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Extensions.Options" Version="9.0.5" />
    <PackageReference Include="System.Net.Http.Json" Version="9.0.5" />
    <PackageReference Include="Microsoft.Extensions.Logging.Abstractions" Version="9.0.5" />
    <PackageReference Include="Microsoft.Extensions.Http" Version="9.0.5" />
    <PackageReference Include="Microsoft.Extensions.Http.Polly" Version="9.0.5" />
    <PackageReference Include="Polly" Version="8.5.2" />
    <PackageReference Include="Polly.Contrib.WaitAndRetry" Version="1.1.1" />
    <PackageReference Include="AWSSDK.BedrockRuntime" Version="4.0.0.4" />
    <PackageReference Include="AWSSDK.TranscribeService" Version="4.0.0.4" />
    <PackageReference Include="AWSSDK.Polly" Version="4.0.0.4" />
  </ItemGroup>

  <PropertyGroup>
    <TargetFramework>net9.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    
    <!-- NuGet Package Configuration -->
    <GeneratePackageOnBuild>true</GeneratePackageOnBuild>
    <PackageId>ConduitLLM.Providers</PackageId>
    <Title>Conduit LLM Providers Library</Title>
    <Description>LLM provider implementations for OpenAI, Anthropic, AWS Bedrock, and other providers in the Conduit LLM gateway</Description>
    <PackageTags>llm;ai;providers;openai;anthropic;bedrock;conduit;gpt;claude</PackageTags>
    <PackageProjectUrl>https://github.com/knnlabs/Conduit</PackageProjectUrl>
    <PackageLicenseExpression>MIT</PackageLicenseExpression>
    <IncludeSymbols>true</IncludeSymbols>
    <SymbolPackageFormat>snupkg</SymbolPackageFormat>
  </PropertyGroup>

</Project>
